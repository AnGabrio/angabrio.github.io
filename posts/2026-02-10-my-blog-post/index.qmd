---
title: "Survival Analysis"
description: ""
author:
  - name: Andrea Gabrio
    url: https://angabrio.github.io/agabriosite2/
    orcid: 0000-0002-7650-4534
    affiliation: Maastricht University
    affiliation-url: https://www.maastrichtuniversity.nl/research/methodology-and-statistics
date: 2026-02-10
categories: [Quarto, R, Academia, Medical Statistics, Survival Analysis] # self-defined categories
#citation: 
#  url: https://samanthacsik.github.io/posts/2022-10-24-my-blog-post/ 
image: featured.jpeg
bibliography: references.bib
nocite: |
  @*
draft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!
---

Hello folks, I hope everything is well with you and welcome back to my regular blog update. This month nothing particularly exciting has happened to me, but I mostly spent my time catching up with some research collaborations and ideas, plus some usual teaching duties. Although we had a rough start of the year here in Maastricht (at least in terms of weather), now the situation seems a bit calmer and nicer. Overall, I cannot complain to much and need to find the time to finish off some left-off work, and I am talking of my `R` package `missingHE`, which will (hopefully) soon get a big update with a bunch of new content! But, before that, let me introduce the topic that I will be discussing today on my blog, that is a gentle presentation of some key concepts of **Survival Analysis**. I hope this topic is of interest to you and that you find this post helpful in case you were interested in approaching this field of statistics. Personally, I find the topic quite interesting and cool, although I am not an expert when it comes down to very advanced survival analysis methods. Today I will just touch upon some basic elements that assume no previous knowledge on the matter, so rest assured that most of the things I will discuss will make sense for someone who never heard of this topic before (I hope)!


# Introduction

**Survival Data** typically occur where times are recorded from a specific *time origin* until the occurrence of some pre-defined *event* of interest for a group of subjects (e.g. time until death following a heart transplant or disease diagnosis). Note that the event of interest does not need to be "death" but may, for instance, refer to the occurrence of remission from a disease or discharge from an hospital. Sometimes, survival data may be also referred to as **time-to-event** data. For example, we have considered in past posts the concept of a *rate* as an estimate of the probability of the occurrence of an event of interest within a given time frame. However, rate calculation rests on the quite strong assumption that the underlying risk does not change over time.

Key features of survival data typically include:

  - Existence of times $\geq 0$, thus unlikely to come from a Normal distribution.
  
  - Shape of empirical distributions that are positively skewed.
  
  - For some subjects, the time-to-event is unknown (e.g. still alive at the end of the period of follow-up), for whom we only know that the event of interest has not occurred before a certain time. In particular, a subject's observed time is defined as **censored** if the event of interest has not occurred during the follow-up.

Censoring may occur due to a variety of reasons, and may therefore be associated with different observed censoring features. For example, the event of interest may not occur during the follow-up because patients are still alive at the end of the study period, or because subjects are lost to follow-up (patients' times are said to be **right censored**). Methods used for the analysis of survival data should account for censoring to avoid bias in the resulting estimates.

Right censoring is by far the most common type of censoring mechanism in medical studies. More technically, we talk about **right censoring** when a subject enters a study at time $t_0$ and experiences the event of interest at $t_0+t$, but the study ends at time $t_0+c$, where $c<t$. Thus, we only know that the subject experienced the event at some unknown time $> t_0 + c$, and we say that the subject's time is right censored. Other possible types of censoring mechanism for the unknown time $t$ at which the subject experienced the event include: **left censoring**, where we only know that $t<c$; **interval censoring**, where we only know that $c_1<t<c_2$. 

In addition to the different types of censoring mechanisms, each of these may also be characterised by whether the censoring time is dependent or not on the reasons that lead to the creation of the censoring mechanism. In general, we say that censoring is *non-informative* if the actual unknown survival time is independent of the mechanism that caused the observation to become censored at some time $c<t$. This assumption implies that that a subject censored at time $c$ should be representative of all other subjects who have yet to experience the event of interest at time $c$. When this is not true, i.e. subjects are censored for reasons related to their unknown survival time, censoring is said to be *informative* (e.g. a patient drops out from a study because their health deteriorates, likely leading to a lower survival time with respect to all the others still alive at the time of dropout).

## The Survival Function

The survival time is measured from a specific origin, often given by randomisation or administration of treatment (RCTs) or by age, since recruitment or infection (observational studies). The variable of interest is the time to the event $T$, which may not be observed for all subjects. Let us assume that we have a data set with data from $N$ subjects, and let $i$-th denote the subject index for $i=1,\ldots,N$. We subset the individuals into two separate groups: $C=$ set of censored subjects, and $D=$ set of fully-observed event of interest occurrences. Survival data are typically defined using the pair of variables $(t_i,\delta_i)$, where: $t_i=$ time to event of interest if $i \in D$ or censoring time if $i \in C$; $\delta_i=$ 1 if $i \in D$ (event experienced) or 0 if $i \in C$ (subject censored). 

Using the pair $(t_i,\delta_i)$, we can now summarise survival data using a **survival function**. In particular, let $S(t)$ denote the survival function given by:

$$
S(t) = P(T>t)=1-F(t),
$$
where $T$ denotes the survival time (i.e. time to the event) random variable with probability density function $f(t)$ and cumulative distribution function $F(t)$. The survival function $S(t)$ measures the probability that a subject experiences the event beyond time $t$. If no subject is censored, we could use the following empirical estimate of the function at each time $t$:

$$
\hat{S}(t) = \frac{\text{Number of subjects with survival time} \geq t}{\text{Total number of subjects in the data set}},
$$

assuming $\hat{S}(t)$ remains constant between event times.

### Example

The following survival times are recorded for 10 patients from a study on multiple myeloma

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 

#generate data
times_ex1 <- c(23, 41, 32, 83, 5, 62, 96, 71, 90, 54)
times_ex1
```

and their empirical survival function may be graphically represented as

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 

#empirical surv function
st_emp <- function(time) {
  n <- length(time)
  n_survt <- c()
  for(i in 1:length(time)) { n_survt[i] <- length(which(time >= time[i]))}
  st <-  n_survt/n
  return(sort(st, decreasing = TRUE))
}

surv_time_ex1 <- st_emp(time = times_ex1)
surv_time_ex1.plot <- c(surv_time_ex1, 0)
time_ex1.plot <- sort(c(0, times_ex1))
emp_st.df <- data.frame(time_ex1.plot, surv_time_ex1.plot)
names(emp_st.df) <- c("Survival_time", "Survival_function")

library(ggplot2)
ggplot(emp_st.df, aes(x=Survival_time, y=Survival_function)) + 
  geom_step(color="red", size=1, alpha=0.9, linetype=1) +
  xlab("Survival time (months)") + ylab("S(t)=P(T>t)") + 
  scale_x_continuous(expand = c(0, 0), limits = c(0, NA)) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"))
```

## The Kaplan-Meier Estimate

When censoring occurs in a data set, we cannot use the empirical estimate of the survival function but we use its **Kaplan-Meier estimate** instead, which is calculated as follows:

  - First, order the *failure times* (times where an event occurs in the data) from smallest to largest. Assuming $n$ failures, we write these as $t(1)< \ldots < t(n)$.
  
  - Second, consider $n-1$ intervals where each starts with a failure time and ends just before the next ordered failure time. Another interval runs from $t(0)$ until just before the first failure time. We write these as $[t(0),t(1)), \ldots, [t(n),\infty)$.
  
  - Third, we define $n_j=$ number of subjects at the beginning of the interval $[t(j),t(j+1))$ who are uncensored and have not experienced the event, and $d_j=$ number of failures (subjects who experienced the event) during the interval $[t(j),t(j+1))$.
  
  - Fourth, the probability of surviving the interval $[t(j),t(j+1))$ is given by $\hat{p}_j=\frac{n_j-d_j}{n_j}$.
  
  - Fifth, the KM estimate of the survival function for $t \in [t(k),t(k+1))$ is $\hat{S}(t)=\prod_{j=1}^k \hat{p}_j$.
  
### Example

Consider the following 18 times until discontinuation of an intrauterine device in a study on the side effects of contraceptives, where censored times are labelled with a value of 0 in the corresponding indicator variable ($\delta$).  
  
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 

#generate data
times_ex2 <- c(10, 13, 18, 19, 23, 30, 36, 38, 54, 56, 59, 75, 93, 97, 104, 107, 107, 107)
delta <- c(1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0)
df.ex2 <- data.frame(times_ex2, delta)
names(df.ex2) <- c("times", "delta")
df.ex2
```  
  
```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 

#step 1: sort by unique event times and add time origin
sort_times <- sort(unique(df.ex2$times))
sort_times0 <- c(0, sort_times[-length(sort_times)])

#step 2-3: count the number at risk (having not experienced event) and number of deaths in each interval [t(j),t(j+1))
n.atrisk <- n.dead <- rep(NA, length(sort_times))
for(i in 1:length(sort_times)) {
  n.atrisk[i] <- nrow(subset(df.ex2, times > sort_times0[i]))
  n.dead[i] <- nrow(subset(subset(df.ex2, times > sort_times0[i]), 
                           times <= sort_times[i] & delta == 1))
}

#step 4: calculate conditional probability of surviving the interval
p.surv.int <- (n.atrisk - n.dead) / n.atrisk

#step 5: calculate cumulative probability of survival from time zero until end of the interval 
st_km <- cumprod(p.surv.int)

#put in df from plotting
km.df <- data.frame(sort_times0, sort_times, n.atrisk, n.dead, p.surv.int, st_km)
names(km.df) <- c("Survival_time0", "Survival_time", "n", "d", "p", "S_KM")

#put everything into a function 
#KM surv function
st_KM <- function(time, event) {
  n <- length(time)
  sort_times <- sort(unique(time))
  sort_times0 <- c(0, sort_times[-length(sort_times)])
  n.atrisk <- n.dead <- rep(NA, length(sort_times))
  for(i in 1:length(sort_times)) {
  n.atrisk[i] <- nrow(subset(df.ex2, times > sort_times0[i]))
  n.dead[i] <- nrow(subset(subset(df.ex2, times > sort_times0[i]), 
                           times <= sort_times[i] & delta == 1))
  }
  p.surv.int <- (n.atrisk - n.dead) / n.atrisk
  st_km <- cumprod(p.surv.int)
  km.df <- data.frame(sort_times0, sort_times, n.atrisk, n.dead, p.surv.int, st_km)
  names(km.df) <- c("Survival_time0", "Survival_time", "n", "d", "p", "S_KM")
  km.df.plot <- as.data.frame(c(0, 0, km.df[1, c("n", "d")], 1, 1))
  names(km.df.plot) <- names(km.df)
  km.df.plot <- rbind.data.frame(km.df.plot, km.df)
  res.km <- list("obs.KM" = km.df.plot) 
  return(res.km)
}

KM_res <- st_KM(time = df.ex2$times, event = df.ex2$delta)
KM_res.obs <- KM_res$obs.KM

ggplot(KM_res.obs, aes(x=Survival_time, y=S_KM)) +
  geom_step(color="red", size=1, alpha=0.9, linetype=1) +
  geom_point(data = KM_res.obs[KM_res.obs$d==0, ], color = "red", shape = "|", size = 4) +
  xlab("Survival time (weeks)") + ylab("S(t)=P(T>t)") +
  scale_x_continuous(expand = c(0, 0), limits = c(0, 120)) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, 1.1)) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"))
```

Given that survival data are usually skewed, we are often interested in estimating the median survival time, i.e. the smallest time $t$ for which $\hat{S}(t)<0.5$.

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 

median_time <- min(KM_res.obs$Survival_time[KM_res.obs$S_KM < 0.5], na.rm = TRUE)

library(tibble)
#KM surv function median time
ggplot(KM_res.obs, aes(x=Survival_time, y=S_KM)) +
  geom_step(color="red", size=1, alpha=0.9, linetype=1) +
  geom_point(data = KM_res.obs[KM_res.obs$d==0, ], color = "red", shape = "|", size = 4) +
  geom_segment(data=tibble(), 
               aes(x=median_time,y=0,xend=median_time,yend=0.5), 
               inherit.aes=FALSE, color = "black", linetype=2) +
    geom_segment(data=tibble(), 
               aes(x=0,y=0.5,xend=median_time,yend=0.5), 
               inherit.aes=FALSE, color = "black", linetype=2) +
  xlab("Survival time (weeks)") + ylab("S(t)=P(T>t)") +
  scale_x_continuous(expand = c(0, 0), limits = c(0, 120)) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, 1.1)) +
  annotate("text", x=93, y=0.05, label= paste("median time = ", median_time, sep = ""), 
           size  = 3) +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(), panel.background = element_blank(), 
        axis.line = element_line(colour = "black"), plot.title = element_text(hjust = 0.5), 
        strip.background =element_rect(fill="white"))
```
  
In many cases we want to compare survival function estimates of two groups of interest.

## Comparing survival functions between groups

### Example 

@kirk1980late reported findings from a trial of prednisolone in $44$ patients with chronic active hepatitis, randomised to either receiving prednisolone ($n=22$) or placebo ($n=22$), with the outcome of interest being survival time (time until death). The survival times (in months) of the two groups of patients are given below, with associated censoring times.

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 

#generate data
times_ex3_pla <- c(2, 3, 4, 7, 10, 22, 28, 29, 32, 37, 40, 41, 54, 61, 63, 71, 127, 140, 146, 158, 167, 188)
delta_pla <- c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0)
times_ex3_pred <- c(2, 6, 12, 54, 56, 68, 89, 96, 96, 125, 128, 131, 140, 141, 143, 145, 146, 148, 162, 168, 173, 181)
delta_pred <- c(1,1,1,1,0,1,1,1,1,0,0,0,0,0,1,0,1,0,0,1,0,0)
df.ex3 <- data.frame(times_ex3_pla, delta_pla, times_ex3_pred, delta_pred)
names(df.ex3) <- c("placebo t", "placebo delta", "prednis t", "prednis delta")
df.ex3
```  

The aim is to compare the survival functions between the groups, i.e. does the survival rate differ between the groups? We may start by comparing the KM estimates of $S(t)$ for the two groups. Here, to make things easier for me, I will use the functions `survfit()` and `ggsurvplot()`, from the packages `survival` and `survminer`, to generate and plot KM estimates for the two groups, respectively. 

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 

#KM surv function between groups time
df.ex3_times_all <- c(df.ex3$`placebo t`, df.ex3$`prednis t`)
df.ex3_delta_all <- c(df.ex3$`placebo delta`, df.ex3$`prednis delta`)
df.ex3_group <- c(rep("placebo", 22), rep("prednisolone", 22))
df.ex3.all <- cbind.data.frame(df.ex3_times_all, df.ex3_delta_all, df.ex3_group)
names(df.ex3.all) <- c("time", "delta", "group")
df.ex3.all$group <- factor(df.ex3.all$group, levels = c("placebo", "prednisolone"))

library(survminer)
library(survival)
km3 <- with(df.ex3.all, Surv(time, delta))
km_fit3 <- survfit(Surv(time, delta) ~ group, data=df.ex3.all)

ggsurvplot(km_fit3, data = df.ex3.all,
           palette = c("red", "black"),
           legend.labs = c("Placebo", "Prednisolone")) 
```

## The log-rank test

Looking at the plots it seems that the estimated survival function decreases more rapidly over time for the placebo group. Now, can adopt an hypothesis test to assess formally whether there is any significant difference in survival between the two groups? For example, we can use a non-parametric **log-rank test** to test the null hypothesis that the survival functions are the same for the two groups. More generally, where there are $K$ groups, the test statistic is 

$$
\chi^2 = \sum_{i=1}^K \frac{(O_i - E_i)^2}{E_i},
$$

where $O_i$ and $E_i$ are the observed and expected (under the null hypothesis) number of deaths in the $i-th$ group. In particular, under $H_0$ we know that $\chi^2 \sim \chi^2_{K-1}$. The test is valid only if the KM plots of the survival functions for the groups do not intersect, an assumption known as *proportional hazards*.

To calculate the expected number of deaths ($E_i$), we do the following:

  1. Order the event times from smallest to largest across all groups.
  
  2. At each ordered death time we count: the number of subjects alive and uncensored in each group immediately prior to that time; and the number of events at that time.
  
  3. The expected number of deaths in group $i$ is then calculated as the fraction of alive and uncensored subjects in group $i$ at the time multiplied by the number of events (across all groups) at that time.
  
  4. Within each group, the expected numbers of events are summed across all ordered event times to calculate $E_i$ for each $i$.
  
For example, with two groups ($i=1,2$) and an event time $t(j)$, we write: 

  - $n_{ij}=$ number of subjects alive and uncensored at start in group $i$.
  - $d_{ij}=$ number of events at $t(j)$ in group $i$.
  - $n_j$ and $d_j$ are the number of subjects alive and uncensored at start and the number of events at $t(j)$ across groups.
  
The expected number of deaths in group $i$ is then: $e_{ij}=\frac{n_{ij}d_j}{n_j}$. If there are $r$ ordered event times, then the overall expected number of deaths in group $i$ is: $E_i=\sum_{j=1}^r=e_{ij}$.

### Example 

The following table shows survival times (in days) from a study of breast cancer patients, stratified according to their age group at the start of the study: group 1 (60 years or under), group 2 (over 60). For the death column, 1 indicates that a death occurred whereas a 0 denotes censoring. 

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 

#generate data
library(kableExtra)
ex4.id <- 1:13
ex4.group <- c(2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1)
ex4.time <- c(413, 701, 1075, 1735, 1801, 2989, 3044, 3351, 5551, 6277, 7293, 7352, 7434)
ex4.death <- c(1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0)
df.ex4 <- cbind.data.frame(ex4.id, ex4.group, ex4.time, ex4.death)
names(df.ex4) <- c("ID", "Group", "Time", "Death")
df.ex4$Group <- factor(df.ex4$Group, levels = c("1", "2"))

#define function to compute table results for lrt
get.tbl.lrt <- function(data, Time, Group, Death) {
  group.lev <- levels(data[, Group])
  n.group.lev <- length(group.lev)
  sort_times <- sort(unique(data[, Time]))
  sort_times0 <- c(0, sort_times[-length(sort_times)])
  n.atrisk <- n.dead <- matrix(NA, nrow = nrow(data), ncol = (n.group.lev+1))
  n.atrisk[, 1] <- n.dead[, 1] <- data[, Time] 
  for(i in 1:length(sort_times)) {
    for(j in 1:n.group.lev) {
   n.atrisk[i, j+1] <- nrow(subset(subset(data, Time > sort_times0[i]), Group == group.lev[j]))
   n.dead[i, j+1] <- nrow(subset(subset(data, Time == sort_times[i]), 
                            Death == 1 & Group == group.lev[j]))
    }
  }
  colnames(n.atrisk) <- c("Time", paste("n", group.lev, sep = "."))
  colnames(n.dead) <- c("Time", paste("d", group.lev, sep = "."))
  tbl.res <- cbind.data.frame(n.atrisk, n.dead[, -1])
  tbl.res <- tbl.res[which(data[, Death] == 1), ]
  n.all <- apply(tbl.res[, paste("n", group.lev, sep = ".")], 1, sum)
  d.all <- apply(tbl.res[, paste("d", group.lev, sep = ".")], 1, sum)
  n.exp <- tbl.res[, paste("n", group.lev, sep = ".")] * d.all / n.all 
  colnames(n.exp) <- paste("e", group.lev, sep = ".")
  tbl.res <- cbind.data.frame(tbl.res, n.exp)
  return(tbl.res)
}

#apply function to the data
tbl.ex4 <- get.tbl.lrt(data = df.ex4, Time = "Time", Group = "Group", Death = "Death")

#compute chi2 statistic and get p-value
Obs <- apply(tbl.ex4[, c("d.1", "d.2")], 2, sum)
Exp <- apply(tbl.ex4[, c("e.1", "e.2")], 2, sum)
chi2 <- sum((Obs - Exp)^2 / (Exp))
df <- length(unique(df.ex4$Group)) - 1
pval <- round(pchisq(chi2, df = df, lower.tail = FALSE), digits = 3)

kbl(df.ex4)
```  

For example, at death time $t(j)=413$, we compute the following quantities:

  - $n_{1j}=6$; $d_{1j}=0$; $n_{2j}=7$; $d_{2j}=1$; $e_{1j}=6/13=0.46$; $e_{2j}=7/13=0.54$

and, at death time $t(j)=1075$:

  - $n_{1j}=5$; $d_{1j}=0$; $n_{2j}=6$; $d_{2j}=1$; $e_{1j}=5/11=0.45$; $e_{2j}=6/11=0.55$.

Repeating this for all death times:

```{r}
#| echo: false 
#| eval: true
#| message: false
#| warning: false
#| error: false 

#generate data
lrt.tbl <- matrix(NA, nrow = 9, ncol = 7)
colnames(lrt.tbl) <- c("t(j)","n1j","d1j","n2j","d2j","e1j","e2j")
lrt.tbl[, 1] <- c(413, 1075, 1735, 1801, 2989, 3044, 3351, 5551, 6277)
lrt.tbl[, 2] <- c(6, 5, 5, 4, 4, 3, 3, 3, 3)
lrt.tbl[, 3] <- c(0, 0, 1, 0, 1, 0, 0, 0, 0)
lrt.tbl[, 4] <- c(7, 6, 5, 5, 4, 4, 3, 2, 1)
lrt.tbl[, 5] <- c(1, 1, 0, 1, 0, 1, 1, 1, 1)
lrt.tbl[, 6] <- c(0.46, 0.45, 0.5, 0.44, 0.5, 0.43, 0.5, 0.6, 0.75)
lrt.tbl[, 7] <- c(0.54, 0.55, 0.5, 0.56, 0.5, 0.57, 0.5, 0.4, 0.25)
kbl(lrt.tbl, row.names = FALSE)
``` 

So, we can sum up the column values to get $O_1=2$, $O_2=7$, $E_1=4.64$, $E_2=4.36$, where it must always be that $O_1+O_2=E_1+E_2$. The test statistic is then:

$$
\chi^2 = \sum_{i=1}^2 \frac{(O_i - E_i)^2}{E_i} = 3.10,
$$
and under $H_0$ we assume that the it has a $\chi^2$ distribution with degrees of freedom equal to the number of groups minus one (1), and compute the corresponding p-value of $P(Z>3.10)=`r pval`$, therefore suggesting that there is not enough evidence to conclude that the two survival distributions differ.

# Conclusions

Survival analysis methods are applicable to:

  - Randomised trials where we observe time-to-event outcomes for patients in each group.
  
  - Observational cohort studies where a specific group is followed over time and time data are collected until the event of interest.

However, they are not applicable to case-control or cross-sectional studies.

For today that' all dear readers, and I hope you find this topic interesting as there is much more to talk about. I was actually surprised that it took quite some time for me to replicate all the above steps and approaches in `R` (without relying too much on pre-defined already existing functions), but I am glad I was able to make it. If someone would be interested in having a look at the code that I wrote in base `R`, feel free to ask me. In the meantime, I would like to say goodbye and till the next time.

# References
