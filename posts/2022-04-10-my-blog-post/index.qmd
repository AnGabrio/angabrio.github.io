---
title: "New paper out"
description: ""
author:
  - name: Andrea Gabrio
    url: https://angabrio.github.io/agabriosite2/
    orcid: 0000-0002-7650-4534
    affiliation: Maastricht University
    affiliation-url: https://www.maastrichtuniversity.nl/research/methodology-and-statistics
date: 2022-04-10
categories: [Quarto, R, Academia, publication] # self-defined categories
#citation: 
#  url: https://samanthacsik.github.io/posts/2022-10-24-my-blog-post/ 
image: featured.jpg
draft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!
---

![](featured.jpg){fig-align="center"}

Hello there! (do you get the movie reference?)

Just a quick update from this month as I have recently received confirmation that a new [paper](https://onlinelibrary.wiley.com/doi/full/10.1002/hec.4510) I was involved with as first author has finally been published on Health Economics!!! Hurray! This is a work I am quite proud of as I was the guy who had the initial idea behind the concept of the paper and I was lucky enough to find some very helpful colleagues from the UK, most notably the very nice [Baptiste Leurent](https://www.lshtm.ac.uk/aboutus/people/leurent.baptiste) and [Catrin Plumpton](https://www.bangor.ac.uk/staff/medical-health-sciences/catrin-plumpton-018729/en) who helped me out with laying down my ideas and give it an interesting appeal for the general health economist's audience. 

The main objective of the paper is nothing revolutionary or extremely innovative but rather on the importance of spreading awareness about the use of a specific type of modelling approach that has been rarely adopted in the context of health economic evaluation based on trial data, namely **linear mixed effects models** (LMMs). Indeed, most of the references to this approach in the health economic literature is related to the use of LMM to deal with clustering at the level of centres/countries which, do not get me wrong, is totally correct. However, I have noticed over time that LMMs have almost never been adopted in trial-based CEAs for the standard analysis of utility and cost data collected at different time points. This I think is a big gap in the literature as many analysts may simply ignore the potential use of LMMs for analysing these data given their lack of implementation in the literature. 

After reaching out to my colleguaes to have their opinion on the matter, we all agreed that it could be nice to lay down the coding and rationale for using LMMs to perform standard cost-effectiveness analyses based on trial data. Of course, as any method, there are *advantages* and *drawbacks* when using LMMs compared to the standard OLS models fitted at the level of aggregated variables (e.g. QALYs) instead of modelling utilities at each time. I will not go into much detail about these pros and cons (perhaps have a look at the paper if you are intrigued) but I will highlight two main points:

 * When dealing with missing outcome values (i.e. always) modelling the disaggregated longitudinal data has the practical advantage the information about the reason for missingness can be more intuitively incorporated into the analysis and additionally allows to avoid some potential loss of power or even bias compared to standard complete case analysis approaches. The nice thing is that LMMs are also valid under standard **Missing At Random** (MAR) assumptions with the additional benefit that estimates can be derived without the need of using multiple imputation procedures unless some auxiliary variables are also considered into the analysis that are related to missingness. Thus, when then performing *bootstrapping*, no practical issues arises in terms of choosing the way to combine multiply imputed data and bootstrap replications which instead commonly occurs in standard analyses.  

* LMMs allows for a quite flexible specification of the *covariance structure* of the data over time which can be tested from the observed data. Retrieval of the effects if interest (e.g. mean QALYs or total costs per arm) can be easily obtained by linearly combining the parameter estimates from the fixed effects part of the model depending on the parameterisation chosen. This can also be done in a straightforward way using common software packages (e.g. `R` or `STATA`) and does not require more than 
one or two lines of code. 

Of course, there are also downsides to be considered. For example, the use of multiple imputation to account for *auxiliary variables* or bivariate modelling to deal with the *correlation* between utilities and costs is not so easy to do. This is perhaps 
an idea for future development of the methods in the context of CEA. Well, my general solution is quite simple, just go Bayesian and get rid of all your headaches! However, I am not sure all practitioners will agree with me on that. Anyway, I invite you to have a look at the paper if you are involved in CEAs as it may provide some interesting thoughts for you to explore in relation to the methodology to use when analysing trial data and the potential implications of ignoring missing values in a context where the longitudinal nature of the data should be taken into account. 

Have a nice read!

![](https://i.gifer.com/X0ie.gif){fig-align="center"}
