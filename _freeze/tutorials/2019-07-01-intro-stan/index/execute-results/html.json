{
  "hash": "caef0decaf622dc53506671ab55aea79",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Super basic introduction to Stan\"\ndescription: \"\"\nauthor:\n  - name: Andrea Gabrio\n    url: https://angabrio.github.io/agabriosite2/\n    orcid: 0000-0002-7650-4534\n    email: a.gabrio@maastrichtuniversity.nl\n    corresponding: true    \n    affiliation: Maastricht University\n    affiliation-url: https://www.maastrichtuniversity.nl/research/methodology-and-statistics\ndate: 2019-07-01\ncategories: [Quarto, R, Academia, Software, Statistics] # self-defined categories\n#image: featured.jpg\ndraft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!\nabstract: > \n  [The focus of this simple tutorial is to provide a brief introduction and overview about how to fit Bayesian models using `Stan` via `R` ...]{style=\"font-size: 85%\"}\nkeywords:\n  - Software\n  - Statistics\n  - Stan\n#license: \"GPL-2\"\n#copyright: \n#  holder: CRAN\n#  year: 2023\n#citation: \n#  title: missingHE\n#  author: Andrea Gabrio\n#  note: R package version 4.4.2\n#  url: https://cran.r-project.org/web/packages/missingHE\n#funding: \"The author received no specific funding for this work.\"\nbibliography: citations_stan.bib\n#nocite: |\n#  @gabrio2017handling\n---\n\n\nThe focus of this simple tutorial is to provide a brief introduction and overview about how to fit Bayesian models using `Stan` via `R`.\n\nPrerequisites:\n\n* The latest version of `R`, which can be downloaded and installed for Windows, Mac or Linux OS from the [CRAN](https://www.r-project.org/}) website\n* I also **strongly** recommend to download and install [Rstudio](https://www.rstudio.com/), an integrated development environment which provides an \"user-friendly\" interaction with `R` (e.g. many drop-down menus, tabs, customisation options)\n\n# Preliminaries\n\n## What is Stan?\n\nStan provides full Bayesian inference for continuous-variable models through Markov Chain Monte Carlo methods such as the No-U-Turn sampler, an adaptive form of Hamiltonian Monte Carlo sampling\n\n`Stan` is a program for analysis of Bayesian models using Markov Chain Monte Carlo (MCMC) methods (@gelman2015stan). `Stan` is a free software and a probabilistic programming language for specifying statistical models using a specific class of MCMC algorithms known as **H**amiltonian **M**onte **C**arlo methods (HMC). The latest version of `Stan` can be dowloaded from the web [repository](https://mc-stan.org/users/interfaces/) and is available for different OS. There are different `R` packages which function as frontends for `Stan`. These packages make it easy to process the output of Bayesian models and present it in publication-ready form. In this brief introduction, I will specifically focus on the `rstan` package (@rstanpackage) and show how to fit `Stan` models using this package.\n\n## Installing Stan and rstan\n\nUnlike other Bayesian software, such as `JAGS` or `OpenBUGS`, it is not required to separately install the program and the corresponding frontend `R` package. Indeed, installing the `R` package `rstan` will automatically install `Stan` on your machine. However, you will also need to make sure to having installed on your pc a `C++` compiler which is used by `rstan` to fit the models. Under a Windows OS, for example, this can be done by installing `Rtools`, a collection of resources for building packages for `R`, which is freely available from the web [repository](https://cran.r-project.org/bin/windows/Rtools/). \n\nNext, install the package `rstan` from within `R` or `Rstudio`, via the package installer or by typing in the command line\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"rstan\", dependencies = TRUE)\n```\n:::\n\n\nThe `dependencies = TRUE` option will automatically install all the packages on which the functions in the `rstan` package rely.\n\n# Basic model\n\n## Simulate data\n\nFor an example dataset, I simulate my own data in `R`. I create a continuous outcome variable $y$ as a function of one predictor $x$ and a disturbance term $\\epsilon$. I simulate a dataset with 100 observations. Create the error term, the predictor and the outcome using a linear form with an intercept $\\beta_0$ and slope $\\beta_1$ coefficients, i.e.\n\n$$\ny = \\beta_0 + \\beta_1 x + \\epsilon  \n$$\n\nThe `R` commands which I use to simulate the data are the following:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_sim=100; set.seed(123)\nx=rnorm(n_sim, mean = 5, sd = 2)\nepsilon=rnorm(n_sim, mean = 0, sd = 1)\nbeta0=1.5\nbeta1=1.2\ny=beta0 + beta1 * x + epsilon\nn_sim=as.integer(n_sim)\n```\n:::\n\n\nThen, I define all the data for `Stan` in a list object\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatalist=list(\"y\"=y,\"x\"=x,\"n_sim\"=n_sim)\n```\n:::\n\n\n## Model file\n\nNow, I write the model for `Stan` and save it as a stan file named `\"basic.mod.stan\"` in the current working directory\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbasic.mod= \"\ndata {\nint<lower=0> n_sim;\nvector[n_sim] y;\nvector[n_sim] x;\n}\nparameters {\nreal beta0;\nreal beta1;\nreal<lower=0> sigma;\n}\ntransformed parameters {\nvector[n_sim] mu;\nmu=beta0 + beta1*x;\n} \nmodel {\nsigma~uniform(0,100);\nbeta0~normal(0,1000);\nbeta1~normal(0,1000);\ny~normal(mu,sigma);\n}\n\n\"\n```\n:::\n\n\n`Stan` models are written using an imperative programming language, which means that the order in which you write the elements in your model file matters, i.e. you first need to define your variables (e.g. integers, vectors, matrices, etc.), the constraints which define the range of values your variable can take (e.g. only positive values for standard deviations), and finally define the relationship among the variables (e.g. one is a liner function of another). \n\nA Stan model is defined by six program blocks:\n\n* Data (required). The *data block* reads external information -- e.g. data vectors, matrices, integers, etc.\n\n* Transformed data (optional). The *transformed data block* allows for preprocessing of the data -- e.g. transformation or rescaling of the data.\n\n* Parameters (required). The *parameters block* defines the sampling space -- e.g. parameters to which prior distributions must be assigned.\n\n* Transformed parameters (optional). The *transformed parameters block* allows for parameter processing before the posterior is computed -- e.g. tranformation or rescaling of the parameters.\n\n* Model (required). In the *model block* we define our posterior distributions -- e.g. choice of distributions for all variables.\n\n* Generated quantities (optional). The *generated quantities block* allows for postprocessing -- e.g. backtranformation of the parameters using the posterior samples.\n\nFor this introduction I consider a very simple model which only requires the specification of four blocks in the `Stan` model. In the data block, I first define the size of the sample `n_sim` as a positive integer number using the expression `int<lower=0> n_sim`; then I declare the two variables `y` and `x` as reals (or vectors) with length equal to N. In the parameters block, I define the coefficients for the linear regression `beta0` and `beta1` (as two real numbers) and the standard deviation parameter `sigma` (as a positive real number). In the transformed parameters block, I define the conditional mean `mu` (a real vector of length `N`) as a linear function of the intercept `beta0`, the slope `beta1`, and the covariate `x`. Finally, in the model block, I assign weakly informative priors to the regression coefficients and the standard deviation parameters, and I model the outcome data `y` using a normal distribution indexed by the conditional mean `mu` and the standard deviation `sigma` parameters. In many cases, `Stan` uses sampling statements which can be vectorised, i.e. you do not need to use for loop statements.\n\nTo write and save the model as the text file \"basic.mod.stan\" in the current working directory, I use the `writeLines` function \n\n\n::: {.cell}\n\n```{.r .cell-code}\nwriteLines(basic.mod, \"basic.mod.stan\")\n```\n:::\n\n\n## Pre-processing\n\nDefine the parameters whose posterior distribtuions we are interested in summarising later and set up the initial values for the MCMC sampler in `Stan`\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nparams=c(\"beta0\",\"beta1\")\ninits=function(){list(\"beta0\"=rnorm(1), \"beta1\"=rnorm(1))}\n```\n:::\n\n\nThe function creates a list that contains one element for each parameter, which gets assigned a random draw from a normal distribution as a strating value for each chain in the model. For simple models like this, it is generally easy to define the intial values for all parameters in the object `inits` which is then passed to the `stan` function in `rstan`. However, for more complex models, this may not be immediate and a lot of trial and error may be required. However, `Stan` can automatically select the initial values for all parameters randomly. This can be achieved by setting `inits=\"random\"`, which is then passed to the `stan` function in `rstan`.\n\nBefore using `rstan` for the first time, you need to load the package, and you may want to set a random seed number for making your estimates reproducible \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rstan)\nset.seed(123)\n```\n:::\n\n\n## Fit the model\n\nNow, we can fit the model in `Stan` using the `stan` function in the `rstan` package and save it in the object `basic.mod`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbasic.mod<-stan(data = datalist, pars = params, iter = 9000, \n  warmup = 1000, init = inits, chains = 2, file = \"basic.mod.stan\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNA \nNA SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nNA Chain 1: \nNA Chain 1: Gradient evaluation took 2.2e-05 seconds\nNA Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.22 seconds.\nNA Chain 1: Adjust your expectations accordingly!\nNA Chain 1: \nNA Chain 1: \nNA Chain 1: Iteration:    1 / 9000 [  0%]  (Warmup)\nNA Chain 1: Iteration:  900 / 9000 [ 10%]  (Warmup)\nNA Chain 1: Iteration: 1001 / 9000 [ 11%]  (Sampling)\nNA Chain 1: Iteration: 1900 / 9000 [ 21%]  (Sampling)\nNA Chain 1: Iteration: 2800 / 9000 [ 31%]  (Sampling)\nNA Chain 1: Iteration: 3700 / 9000 [ 41%]  (Sampling)\nNA Chain 1: Iteration: 4600 / 9000 [ 51%]  (Sampling)\nNA Chain 1: Iteration: 5500 / 9000 [ 61%]  (Sampling)\nNA Chain 1: Iteration: 6400 / 9000 [ 71%]  (Sampling)\nNA Chain 1: Iteration: 7300 / 9000 [ 81%]  (Sampling)\nNA Chain 1: Iteration: 8200 / 9000 [ 91%]  (Sampling)\nNA Chain 1: Iteration: 9000 / 9000 [100%]  (Sampling)\nNA Chain 1: \nNA Chain 1:  Elapsed Time: 0.04 seconds (Warm-up)\nNA Chain 1:                0.277 seconds (Sampling)\nNA Chain 1:                0.317 seconds (Total)\nNA Chain 1: \nNA \nNA SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nNA Chain 2: \nNA Chain 2: Gradient evaluation took 6e-06 seconds\nNA Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.\nNA Chain 2: Adjust your expectations accordingly!\nNA Chain 2: \nNA Chain 2: \nNA Chain 2: Iteration:    1 / 9000 [  0%]  (Warmup)\nNA Chain 2: Iteration:  900 / 9000 [ 10%]  (Warmup)\nNA Chain 2: Iteration: 1001 / 9000 [ 11%]  (Sampling)\nNA Chain 2: Iteration: 1900 / 9000 [ 21%]  (Sampling)\nNA Chain 2: Iteration: 2800 / 9000 [ 31%]  (Sampling)\nNA Chain 2: Iteration: 3700 / 9000 [ 41%]  (Sampling)\nNA Chain 2: Iteration: 4600 / 9000 [ 51%]  (Sampling)\nNA Chain 2: Iteration: 5500 / 9000 [ 61%]  (Sampling)\nNA Chain 2: Iteration: 6400 / 9000 [ 71%]  (Sampling)\nNA Chain 2: Iteration: 7300 / 9000 [ 81%]  (Sampling)\nNA Chain 2: Iteration: 8200 / 9000 [ 91%]  (Sampling)\nNA Chain 2: Iteration: 9000 / 9000 [100%]  (Sampling)\nNA Chain 2: \nNA Chain 2:  Elapsed Time: 0.041 seconds (Warm-up)\nNA Chain 2:                0.327 seconds (Sampling)\nNA Chain 2:                0.368 seconds (Total)\nNA Chain 2:\n```\n\n\n:::\n:::\n\n\nDifferent packages are available to perform diagnostic checks for Bayesian models. Here, I install and load the `bayesplot` package (@gabry2017bayesplot) to obtain graphical diagnostics and results.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"bayesplot\")\nlibrary(bayesplot)\n```\n:::\n\n::: {.cell}\n\n:::\n\n\nFor example, density and trace plots can be obtained by typing \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmcmc_combo(as.array(basic.mod),regex_pars=\"beta0|beta1\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nBoth types of graphs suggest that there are not issues in the convergence of the algorithm (smooth normal densities and hairy caterpillar graphs for both MCMC chains).\n\n# Conclusions\n\nThis tutorial was simply a brief introduction on how simple linear regression models can be fitted using the  Bayesian software `Stan` via the `rstan` package. Although this may seem a complex procedure compared with simply fitting a linear model under the frequentist framework, however, the real advantages of Bayesian methods become evident when the complexity of the analysis is increased (which is often the case in real applications). Indeed, the flexibility in Bayesian modelling allows to account for increasingly complex models in a relatively easy way. In addition, Bayesian methods are ideal when the interest is in taking into account the potential impact that different sources of uncertainty may have on the final results, as they allow the natural propagation of uncertainty throughout each quantity in the model.\n\n# References\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}