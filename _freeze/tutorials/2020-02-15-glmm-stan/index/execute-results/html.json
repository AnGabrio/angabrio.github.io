{
  "hash": "c8dae5cfeb13e9e08d686b9ed217df28",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Generalised Linear Mixed Models (Stan)\"\ndescription: \"\"\nauthor:\n  - name: Andrea Gabrio\n    url: https://angabrio.github.io/agabriosite2/\n    orcid: 0000-0002-7650-4534\n    email: a.gabrio@maastrichtuniversity.nl\n    corresponding: true    \n    affiliation: Maastricht University\n    affiliation-url: https://www.maastrichtuniversity.nl/research/methodology-and-statistics\ndate: 2020-02-15\ncategories: [Quarto, R, Academia, Software, Statistics] # self-defined categories\n#image: featured.jpg\ndraft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!\nabstract: > \n  [This tutorial will focus on the use of Bayesian estimation to fit simple linear regression models ...]{style=\"font-size: 85%\"}\nkeywords:\n  - Software\n  - Statistics\n  - Stan\n#license: \"GPL-2\"\n#copyright: \n#  holder: CRAN\n#  year: 2023\n#citation: \n#  title: missingHE\n#  author: Andrea Gabrio\n#  note: R package version 4.4.2\n#  url: https://cran.r-project.org/web/packages/missingHE\n#funding: \"The author received no specific funding for this work.\"\nbibliography: citations_stan13.bib\n#nocite: |\n#  @gabrio2017handling\n---\n\n\nThis tutorial will focus on the use of Bayesian estimation to fit simple linear regression models. `BUGS` (Bayesian inference Using *Gibbs Sampling*) is an algorithm and supporting language (resembling `R`) dedicated to performing the Gibbs sampling implementation of *Markov Chain Monte Carlo* (MCMC) method. Dialects of the `BUGS` language are implemented within three main projects:\n\n1. **OpenBUGS** - written in component pascal.\n \n2. **JAGS** - (Just Another Gibbs Sampler) - written in `C++`. \n\n3. **Stan** - a dedicated Bayesian modelling framework written in `C++` and implementing *Hamiltonian* MCMC samplers.\n\nWhilst the above programs can be used stand-alone, they do offer the rich data pre-processing and graphical capabilities of `R`, and thus, they are best accessed from within `R` itself. As such there are multiple packages devoted to interfacing with the various software implementations:\n\n* *R2OpenBUGS* - interfaces with `OpenBUGS`\n\n* *R2jags* - interfaces with `JAGS`\n\n* *rstan* - interfaces with `Stan`\n\nThis tutorial will demonstrate how to fit models in `Stan` (@gelman2015stan) using the package `rstan` (@rstanpackage) as interface, which also requires to load some other packages.\n\n# Overview\n\nIn some respects, *Generalized Linear Mixed effects Models* (GLMM) are a hierarchical extension of *Generalized linear models* (GLM) in a similar manner that Linear Mixed effects Models (LMM) are a hierarchical extension of Linear Models (LM). However, whilst the Gaussian (normal) distribution facilitates a relatively straight way of generating the marginal likelihood of the observed response by integrating likelihoods across all possible (and unobserved) levels of a random effect to yield parameter estimates, the same cannot be said for other distributions. Consequently various approximations have been developed to estimate the fixed and random parameters for GLMM's:\n\n  1. **Penalized quasi-likelihood** (PQL). This method approximates a quasi-likelihood by iterative fitting of (re)weighted linear mixed effects models based on the fit of GLM fit. Specifically, it estimates the fixed effects parameters by fitting a GLM that incorporates a correlation (variance-covariance) structure resulting from a LMM and then refits a LMM to re-estimate the variance-covariance structure by using the variance structure from the previous GLM. The cycle continues to iterate until either the fit improvement is below a threshold or a defined number of iterations has occurred. Whilst this is a relatively simple approach, that enables us to leverage methodologies for accommodating heterogeneity and spatial/temporal autocorrelation, it is known to perform poorly (estimates biased towards large variance) for Poisson distributions when the expected value is less than $5$ and for binary data when the expected number of successes or failures are less than $5$. Moreover, as it approximates quasi-likelihood rather than likelihood, likelihood based inference and information criterion methods (such as likelihood ratio tests and AIC) are not appropriate with this approach. Instead, Wald tests are required for inference.\n  \n  2. **Laplace approximation**. This approach utilises a second-order Taylor series expansion to approximate (a mathematical technique for approximating the properties of a function around a point by taking multiple derivatives of the function and summing them together) the likelihood function. If we assume that the likelihood function is approximately normal and thus a quadratic function on a log scale, we can use second-order Taylor series expansion to approximate this likelihood. Whilst this approach is considered to be more accurate than PQL, it is considerably slower and unable to accommodate alternative variance and correlation structures.\n  \n  3. **Gauss-Hermite quadrature** (GHQ). This approach approximates the marginal likelihood by approximating the value of integrals at specific points (quadratures). This technique can be further adapted by allowing the number of quadratures and their weights to be optimized via a set of rules.\n  \n  4. **Markov-chain Monte-Carlo** (MCMC). This takes a bruit force approach by recreating the likelihood by traversing the likelihood function with sequential sampling proportional to the likelihood. Although this approach is very robust (when the posteriors have converged), they are computationally very intense. Interestingly, some (including Andrew Gelman) argue that PQL, Laplace and GHQ do not yield estimates. Rather they are only approximations of estimates. By contrast, as MCMC methods are able to integrate over all levels by bruit force, the resulting parameters are indeed true estimates.\n\nWe will focus on the last approach which is the more general among the ones considered here and which is based on a Bayesian approach, which can be very flexible and accurate, yet very slow and complex.\n\n# Hierarchical Poisson regression\n\nThe model I will be developing is a Bayesian hierarchical Poisson regression model which I used for the modelling of match results in volleyball, also available as a published [paper](https://www.tandfonline.com/doi/full/10.1080/02664763.2020.1723506?casa_token=5NyZAGE970gAAAAA%3AjcSlhut9cztg1nQheK_Z3NZPUuKvwUAcodvBD7g47amY1Cb-ViZZFt-ikcaYhU7o7sIzwEOOcEgH). The objective of the analysis is to model the match results from the season 2017-2018 of *Serie A1*, the premium Italian female volleyball league. In total there were $136$ games (rows) in the dataset each with information regarding which was the home and away team, what these teams scored, whether the match ended with $4$ or $5$ sets, and additional in-game statistics such as number of attacks, digs, serves, and blocks for each team in each match. The point outcomes of the teams in the games are assumed to be distributed according to a Poisson distribution. This model is similar to other models used for the modelling of football results, where the points scored by the home and away teams are defined as a function of latent attacking and defensive skills of the teams estimated across the games. \n\nThe peculiar (and novel) aspect of the model is that it takes into account the features of volleyball to generate plausible game results and league points scored by the teams across the season. In particular, for modelling purposes it is important to accout for the following aspects. 1) according to the current scoring system, matches are played until a team wins a total of three sets, with each set typically going to $25$ points. However, if the two teams won two sets each, the third set then goes only up to $15$ points. 2) a team must win each set by $2$ points. If the score is tied with even numbers, both teams have to continue playing the set until a $2$-point lead is obtained. Otherwise, points keep accumulating until one team wins with a margin of victory of $2$ points, even if the score is greater than $25$ or $15$ points. 3) in professional volleyball leagues, the teams get points according to set numbers at the end of all matches in the league. More specifically, the team points are awarded as follows: if the match is won $3–0$ or $3–1$, $3$ points are assigned to the winner and $0$ points to the loser; if the match is won $3–2$, $2$ points are assigned to the winner and $1$ point to the loser.\n\nThe model is a Bayesian hierarchical analysis of volleyball data which allows to jointly predict match results and team rankings in national leagues. I use data from the women's volleyball Italian Serie A1 $2017–2018$ season as a motivating example to implement and validate the model. \n\n# Loading the data\n\nI start by loading libraries, reading in the data and preprocessing it for `Stan`. In the original verison of the analysis I used `JAGS` and a slightly more complicated model which I do not consider here, but that you may consult in my paper if interested (@gabrio2020bayesian). \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(plyr)\nlibrary(dplyr)\nlibrary(rstan)\nlibrary(bayesplot)\nlibrary(boot)\nlibrary(ggplot2)\nlibrary(scales)\nlibrary(RColorBrewer)\nlibrary(viridis)\nset.seed(12345)  # for reproducibility\n\n#load data\ndata<-read.csv(file = \"Volley_prepro_v1.csv\",header = T)\ndata$home.team<-as.factor(data$home.team)\ndata$away.team<-as.factor(data$away.team)\ndata$bloeff1<-(data$bloper1-data$bloinv1)/(data$blo1+data$bloper1)\ndata$bloeff2<-(data$bloper2-data$bloinv2)/(data$blo2+data$bloper2)\ndata_stat1<-ddply(data, .(h), summarise, meanatteff1=mean(atteff1),meansereff1=mean(sereff1),\n                  meandefeff1=mean(defeff1),meanbloeff1=mean(bloeff1))\ndata_stat2<-ddply(data, .(a), summarise, meanatteff2=mean(atteff2),meansereff2=mean(sereff2),\n                  meandefeff2=mean(defeff2),meanbloeff2=mean(bloeff2))\n#center cov grand mean\natteff1.cen<-data$atteff1-mean(data$atteff1)\nsereff1.cen<-data$sereff1-mean(data$sereff1)\nbloeff1.cen<-data$bloeff1-mean(data$bloeff1)\ndefeff1.cen<-data$defeff1-mean(data$defeff1)\n\natteff2.cen<-data$atteff2-mean(data$atteff2)\nsereff2.cen<-data$sereff2-mean(data$sereff2)\nbloeff2.cen<-data$bloeff2-mean(data$bloeff2)\ndefeff2.cen<-data$defeff2-mean(data$defeff2)\n```\n:::\n\n\n## Data check\n\nHow are the number of points for each team in a volleyball match distributed? Well, let’s start by assuming that both teams have many chances at making a point and that each team have the same probability of scoring each point chance. Given these assumptions the distribution of the number of points for each team should be well captured by a Poisson distribution. A quick and dirty comparison between the actual distribution of the number of scored goals and a Poisson distribution having the same mean number of scored goals support this notion.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfcol = c(2, 1), mar = rep(2.2, 4))\nhist(c(data$y2, data$y1), xlim = c(40, 120), breaks = 8,main = \"Distribution of the number of points\\nscored by a team in a match.\")\nmean_goals <- mean(c(data$y2, data$y1))\nhist(rpois(9999, mean_goals), xlim = c(40, 120), breaks = 8 ,main = \"Random draw from a Poisson distribution with\\nthe same mean as the distribution above.\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n## Model fitting\n\nAll teams aren’t equally good and it will be assumed that all teams have a latent skill variable and the skill of a team minus the skill of the opposing team defines the predicted outcome of a game. As the number of goals are assumed to be Poisson distributed it is natural that the skills of the teams are on the log scale of the mean of the distribution. The distribution of the number of goals for the home team $i$ when facing the away team $j$ is then\n\n$$\n\\text{Points} \\sim \\text{Pois}(\\lambda)\n$$\n\nwhere $\\log(\\lambda)=\\mu + \\text{home} + \\text{skill}_i - \\text{skill}_j$. $\\mu$ is a constant, while home is the advantage for the team hosting the game which is typically assumed to be constant for all the teams and throughout the season. The point outcome of a match between home team $i$ and away team $j$ is modeled as:\n\n$$\n\\text{HomePoins}_{ij} \\sim \\text{Pois}(\\lambda_{\\text{home},ij}),\n$$\n\n$$\n\\text{AwayPoints}_{ij} \\sim \\text{Pois}(\\lambda_{\\text{away},ij}),\n$$\n\nwhere \n\n$$\n\\log(\\lambda_{\\text{home},ij}) = \\mu + \\text{home} + \\text{skill}_i - \\text{skill}_j, \n$$\n\n$$\n\\log(\\lambda_{\\text{away},ij}) = \\mu + \\text{skill}_j - \\text{skill}_i.\n$$\n\nThe skill parameters for the home and away teams are specified as a function of a set of attack and defense skills, which in turn are a linear function of different in-game statistics including the number of attacks, digs, serves and blocks for each team:\n\n$$\n\\text{skill}_i = \\alpha_{0i} + \\alpha_{1i}\\text{attacks} + \\alpha_{2i}\\text{serves} + ,\n$$\n\n$$\n\\text{skill}_j = \\beta_{0j} + \\beta_{1j}\\text{digs} + \\beta_{2j}\\text{blocks},\n$$\n\nThe distribution of two indicator variables, related to whether or not the fifth set was played ($d^s$) and whether the home team was the winner ($d^g$) in each match, are also included in the model. These are modelled as:\n\n$$\nd^s \\sim \\text{Bernoulli}(\\pi^s) \\;\\;\\; \\text{and} \\;\\;\\; d^g \\sim \\text{Bernoulli}(\\pi^g),\n$$\n\nwhere the corresponding probabilities are specified as\n\n$$\n\\text{logit}(\\pi^s) = \\gamma_{0} + \\gamma_1\\text{HomePoins}_{i} + \\gamma_2\\text{AwayPoins}_{j},\n$$\n\n$$\n\\text{logit}(\\pi^g) = \\delta_{0} + \\delta_1\\text{HomePoins}_{i} + \\delta_2\\text{AwayPoins}_{j} + \\delta_3d^g. \n$$\n\nI set the prior distributions over $\\mu$ and $\\text{home}$ to:\n\n$$\n\\text{home} \\sim N(0, 10000) \\;\\;\\; \\text{and} \\;\\;\\; \\mu \\sim N(0, 10000),\n$$\n\nweakly informative priors on $\\boldsymbol \\gamma$, $\\boldsymbol \\delta$, and set the priors on the skill of all $n$ teams using a hierarchical approach to :\n\n$$\n\\text{skill}_{1,\\ldots,n} \\sim N(\\mu_{\\text{teams}}, \\sigma^2_{\\text{teams}}),\n$$\n\nso that teams are assumed to have similar but not identical mean and variance parameters for thier skill parameters. Turning this into a `Stan` model requires some minor adjustments. I have to \"anchor\" the sum of team skills to a constant otherwise the mean skill can drift away freely (*sum to zero constraint*) and the model cannot be identified. Doing these adjustments results in the following model description:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrstanString<-\"\ndata{\nint<lower=1> nteams; // number of teams\nint<lower=1> ngames; // number of games\nint<lower=1, upper=nteams> home_team[ngames]; // home team ID (1, ..., 12)\nint<lower=1, upper=nteams> away_team[ngames]; // away team ID (1, ..., 12)\nvector [ngames] att_eff1; // in game statistics for number of attacks (home)\nvector [ngames] ser_eff1; // in game statistics for number of serves (home)\nvector [ngames] def_eff2; // in game statistics for number of digs (away)\nvector [ngames] blo_eff2; // in game statistics for number of blocks (away)\nvector [ngames] att_eff2; // in game statistics for number of attacks (away)\nvector [ngames] ser_eff2; // in game statistics for number of serves (away)\nvector [ngames] def_eff1; // in game statistics for number of digs (home)\nvector [ngames] blo_eff1; // in game statistics for number of blocks (home)\nint<lower=0> y1[ngames]; // number of points scored by home team\nint<lower=0> y2[ngames]; // number of points scored by away team\nint<lower=0, upper=1> ds[ngames]; // indicator for number of sets played (3/4 or 5)\nint<lower=0, upper=1> dg[ngames]; // indicator for winning of the match for home team\n}\nparameters{\nreal home;\nreal mu;\nreal mu0_att;\nreal mu0_def;\nreal<lower=0> sigma0_att;\nreal<lower=0> sigma0_def;\nreal mu1_att;\nreal mu1_def;\nreal<lower=0> sigma1_att;\nreal<lower=0> sigma1_def;\nreal mu1_ser;\nreal mu1_blo;\nreal<lower=0> sigma1_ser;\nreal<lower=0> sigma1_blo;\nvector [nteams] beta0_att_star;\nvector [nteams] beta1_att_star;\nvector [nteams] beta1_ser_star;\nvector [nteams] beta0_def_star;\nvector [nteams] beta1_def_star;\nvector [nteams] beta1_blo_star;\nreal gamma[3];\nreal delta[4];\n}\ntransformed parameters{\n//Trick to code the sum-to-zero constraint\nvector [nteams] beta0_att;\nvector [nteams] beta1_att;\nvector [nteams] beta1_ser;\nvector [nteams] beta0_def;\nvector [nteams] beta1_def;\nvector [nteams] beta1_blo;\nvector<lower=0>[ngames] theta1;\nvector<lower=0>[ngames] theta2;\nbeta0_att = beta0_att_star - mean(beta0_att_star);\nbeta1_att = beta1_att_star - mean(beta1_att_star);\nbeta1_ser = beta1_ser_star - mean(beta1_ser_star);\nbeta0_def = beta0_def_star - mean(beta0_def_star);\nbeta1_def = beta1_def_star - mean(beta1_def_star);\nbeta1_blo = beta1_blo_star - mean(beta1_blo_star);\n for (g in 1:ngames) {\n    theta1[g] = exp(home + mu + beta0_att[home_team[g]] + beta1_att[home_team[g]]*att_eff1[g] + beta1_ser[home_team[g]]*ser_eff1[g] + \n             beta0_def[away_team[g]] + beta1_def[away_team[g]]*def_eff2[g] + beta1_blo[away_team[g]]*blo_eff2[g]); \n    theta2[g] = exp(mu + beta0_att[away_team[g]] + beta1_att[away_team[g]]*att_eff2[g] + beta1_ser[away_team[g]]*ser_eff2[g] + \n             beta0_def[home_team[g]] + beta1_def[home_team[g]]*def_eff1[g] + beta1_blo[home_team[g]]*blo_eff1[g]); \n }\n}\nmodel {\n//priors\nhome ~ normal(0, 100);\nmu ~ normal(0, 100);\nmu0_att ~ normal(0, 100);\nmu0_def ~ normal(0, 100);\nsigma0_att ~ uniform(0, 100);\nsigma0_def ~ uniform(0, 100);\nmu1_att ~ normal(0, 100);\nmu1_def ~ normal(0, 100);\nsigma1_att ~ uniform(0, 100);\nsigma1_def ~ uniform(0, 100);\nmu1_ser ~ normal(0, 100);\nmu1_blo ~ normal(0, 100);\nsigma1_ser ~ uniform(0, 100);\nsigma1_blo ~ uniform(0, 100);\ngamma ~ normal(0, 100);\ndelta ~ normal(0, 100);\nbeta0_att_star ~ normal(mu0_att, sigma0_att);\nbeta0_def_star ~ normal(mu0_def, sigma0_def);\nbeta1_att_star ~ normal(mu1_att, sigma1_att);\nbeta1_def_star ~ normal(mu1_def, sigma1_def);\nbeta1_ser_star ~ normal(mu1_ser, sigma1_ser);\nbeta1_blo_star ~ normal(mu1_blo, sigma1_blo);\n// likelihood\n for (g in 1:ngames) {\n  y1[g] ~ poisson(theta1[g]);\n  y2[g] ~ poisson(theta2[g]);\n  ds[g] ~ bernoulli_logit(gamma[1] + gamma[2]*y1[g] + gamma[3]*y2[g]);\n  dg[g] ~ bernoulli_logit(delta[1] + delta[2]*y1[g] + delta[3]*y2[g] + delta[4]*ds[g]);\n }\n}\ngenerated quantities{\n// loglikelihood \nvector[ngames] loglik_y1;\nvector[ngames] loglik_y2;\nvector[ngames] loglik_ds;\nvector[ngames] loglik_dg;\n for (g in 1:ngames) {\n  loglik_y1[g] = poisson_lpmf(y1[g]| theta1[g]);\n  loglik_y2[g] = poisson_lpmf(y2[g]| theta2[g]);\n  loglik_ds[g] = bernoulli_logit_lpmf(ds[g]| gamma[1] + gamma[2]*y1[g] + gamma[3]*y2[g]);\n  loglik_dg[g] = bernoulli_logit_lpmf(dg[g]| delta[1] + delta[2]*y1[g] + delta[3]*y2[g] + delta[4]*ds[g]);\n }\n}\n\n\"\n\n## write the model to a text file\nwriteLines(rstanString, con = \"Modelbasic.stan\")\n```\n:::\n\n\nNext, we put the data into a list to be passed to `Stan`, define the nodes (parameters and derivatives) to monitor and the chain parameters.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#prepare data\ny1<-data$y1\ny2<-data$y2\nngames<-max(data$Game)\nnteams<-max(data$h)\nhome_team<-data$h\naway_team<-data$a\n\natt_eff1<-data$atteff1\natt_eff2<-data$atteff2\nser_eff1<-data$sereff1\nser_eff2<-data$sereff2\nblo_eff1<-data$bloeff1\nblo_eff2<-data$bloeff2\ndef_eff1<-data$defeff1\ndef_eff2<-data$defeff2\n\natt_eff1<-atteff1.cen\natt_eff2<-atteff2.cen\nser_eff1<-sereff1.cen\nser_eff2<-sereff2.cen\nblo_eff1<-bloeff1.cen\nblo_eff2<-bloeff2.cen\ndef_eff1<-defeff1.cen\ndef_eff2<-defeff2.cen\n\nds<-ifelse(data$settot==5,1,0)\ndg<-ifelse(data$set1>data$set2,1,0)\n\n#pre-processing\ndatalist <- list(y1=y1,y2=y2,ngames=ngames,nteams=nteams,home_team=home_team,away_team=away_team,att_eff1=att_eff1,att_eff2=att_eff2,def_eff1=def_eff1,def_eff2=def_eff2,ser_eff1=ser_eff1,ser_eff2=ser_eff2,blo_eff1=blo_eff1,blo_eff2=blo_eff2,ds=ds, dg=dg)\nparams <- c(\"mu\",\"home\",\"gamma\",\"delta\",\"beta0_att\",\"beta0_def\",\n            \"beta1_att\",\"beta1_def\",\"beta1_ser\",\"beta1_blo\",\"theta1\",\n            \"theta2\",\"loglik_y1\",\"loglik_y2\",\"loglik_ds\",\"loglik_dg\")\nburnInSteps = 500\nnChains = 2\nnumSavedSteps = 2000\nthinSteps = 1\nnIter = ceiling((numSavedSteps * thinSteps)/nChains)\n```\n:::\n\n\nStart the `Stan` model (check the model, load data into the model, specify the number of chains and compile the model). Run the `Stan` code via the `rstan` package and the `stan` function. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_stan<- stan(data = datalist, file = \"Modelbasic.stan\", \n                       chains = nChains, pars = params, iter = nIter, \n                       warmup = burnInSteps, thin = thinSteps)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNA \nNA SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nNA Chain 1: \nNA Chain 1: Gradient evaluation took 0.000182 seconds\nNA Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.82 seconds.\nNA Chain 1: Adjust your expectations accordingly!\nNA Chain 1: \nNA Chain 1: \nNA Chain 1: Iteration:   1 / 1000 [  0%]  (Warmup)\nNA Chain 1: Iteration: 100 / 1000 [ 10%]  (Warmup)\nNA Chain 1: Iteration: 200 / 1000 [ 20%]  (Warmup)\nNA Chain 1: Iteration: 300 / 1000 [ 30%]  (Warmup)\nNA Chain 1: Iteration: 400 / 1000 [ 40%]  (Warmup)\nNA Chain 1: Iteration: 500 / 1000 [ 50%]  (Warmup)\nNA Chain 1: Iteration: 501 / 1000 [ 50%]  (Sampling)\nNA Chain 1: Iteration: 600 / 1000 [ 60%]  (Sampling)\nNA Chain 1: Iteration: 700 / 1000 [ 70%]  (Sampling)\nNA Chain 1: Iteration: 800 / 1000 [ 80%]  (Sampling)\nNA Chain 1: Iteration: 900 / 1000 [ 90%]  (Sampling)\nNA Chain 1: Iteration: 1000 / 1000 [100%]  (Sampling)\nNA Chain 1: \nNA Chain 1:  Elapsed Time: 62.452 seconds (Warm-up)\nNA Chain 1:                67.426 seconds (Sampling)\nNA Chain 1:                129.878 seconds (Total)\nNA Chain 1: \nNA \nNA SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nNA Chain 2: \nNA Chain 2: Gradient evaluation took 0.00014 seconds\nNA Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 1.4 seconds.\nNA Chain 2: Adjust your expectations accordingly!\nNA Chain 2: \nNA Chain 2: \nNA Chain 2: Iteration:   1 / 1000 [  0%]  (Warmup)\nNA Chain 2: Iteration: 100 / 1000 [ 10%]  (Warmup)\nNA Chain 2: Iteration: 200 / 1000 [ 20%]  (Warmup)\nNA Chain 2: Iteration: 300 / 1000 [ 30%]  (Warmup)\nNA Chain 2: Iteration: 400 / 1000 [ 40%]  (Warmup)\nNA Chain 2: Iteration: 500 / 1000 [ 50%]  (Warmup)\nNA Chain 2: Iteration: 501 / 1000 [ 50%]  (Sampling)\nNA Chain 2: Iteration: 600 / 1000 [ 60%]  (Sampling)\nNA Chain 2: Iteration: 700 / 1000 [ 70%]  (Sampling)\nNA Chain 2: Iteration: 800 / 1000 [ 80%]  (Sampling)\nNA Chain 2: Iteration: 900 / 1000 [ 90%]  (Sampling)\nNA Chain 2: Iteration: 1000 / 1000 [100%]  (Sampling)\nNA Chain 2: \nNA Chain 2:  Elapsed Time: 61.322 seconds (Warm-up)\nNA Chain 2:                75.791 seconds (Sampling)\nNA Chain 2:                137.113 seconds (Total)\nNA Chain 2:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(model_stan, pars =c(\"mu\",\"home\",\"gamma\",\"delta\",\"beta0_att\",\n                          \"beta0_def\",\"beta1_att\",\"beta1_def\",\n                          \"beta1_ser\",\"beta1_blo\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNA Inference for Stan model: anon_model.\nNA 2 chains, each with iter=1000; warmup=500; thin=1; \nNA post-warmup draws per chain=500, total post-warmup draws=1000.\nNA \nNA                  mean se_mean    sd    2.5%     25%     50%    75%  97.5% n_eff\nNA mu               4.44    0.00  0.01    4.42    4.43    4.44   4.45   4.47    75\nNA home             0.03    0.00  0.02    0.00    0.02    0.03   0.05   0.06    55\nNA gamma[1]      -111.64    8.40 37.84 -204.58 -129.36 -102.85 -85.91 -58.49    20\nNA gamma[2]         0.59    0.05  0.25    0.22    0.41    0.54   0.71   1.19    23\nNA gamma[3]         0.56    0.04  0.18    0.29    0.42    0.53   0.67   0.96    25\nNA delta[1]       -12.56    0.98  5.61  -23.44  -16.21  -12.60  -8.90  -1.70    33\nNA delta[2]         0.48    0.02  0.11    0.30    0.41    0.48   0.56   0.73    36\nNA delta[3]        -0.34    0.01  0.07   -0.49   -0.38   -0.33  -0.29  -0.21    61\nNA delta[4]        -3.28    0.24  1.49   -6.06   -4.34   -3.26  -2.27  -0.47    40\nNA beta0_att[1]    -0.01    0.00  0.02   -0.06   -0.03   -0.01   0.01   0.03   954\nNA beta0_att[2]     0.02    0.00  0.02   -0.02    0.00    0.02   0.03   0.06  1000\nNA beta0_att[3]     0.02    0.00  0.02   -0.02    0.01    0.02   0.04   0.06   931\nNA beta0_att[4]     0.00    0.00  0.02   -0.04   -0.01    0.00   0.02   0.05   949\nNA beta0_att[5]    -0.07    0.00  0.03   -0.13   -0.09   -0.07  -0.06  -0.02   682\nNA beta0_att[6]    -0.09    0.00  0.03   -0.14   -0.11   -0.09  -0.07  -0.04   717\nNA beta0_att[7]     0.03    0.00  0.02   -0.02    0.01    0.03   0.04   0.08   985\nNA beta0_att[8]     0.14    0.00  0.03    0.08    0.12    0.14   0.16   0.21   361\nNA beta0_att[9]    -0.05    0.00  0.02   -0.10   -0.07   -0.05  -0.04  -0.01   780\nNA beta0_att[10]    0.01    0.00  0.02   -0.04   -0.01    0.01   0.03   0.06   793\nNA beta0_att[11]   -0.01    0.00  0.03   -0.07   -0.03   -0.01   0.00   0.04  1008\nNA beta0_att[12]    0.02    0.00  0.03   -0.04    0.00    0.02   0.04   0.08   821\nNA beta0_def[1]     0.04    0.00  0.02    0.00    0.03    0.04   0.06   0.09   740\nNA beta0_def[2]     0.06    0.00  0.03    0.01    0.04    0.06   0.08   0.11   835\nNA beta0_def[3]     0.08    0.00  0.02    0.04    0.07    0.08   0.10   0.13   951\nNA beta0_def[4]    -0.08    0.00  0.02   -0.13   -0.10   -0.08  -0.07  -0.03   759\nNA beta0_def[5]     0.03    0.00  0.02   -0.02    0.01    0.03   0.05   0.08   668\nNA beta0_def[6]     0.01    0.00  0.02   -0.03    0.00    0.02   0.03   0.06  1086\nNA beta0_def[7]     0.05    0.00  0.03    0.00    0.03    0.05   0.07   0.10   782\nNA beta0_def[8]    -0.01    0.00  0.03   -0.06   -0.02   -0.01   0.01   0.05   745\nNA beta0_def[9]    -0.03    0.00  0.02   -0.08   -0.05   -0.03  -0.02   0.01   850\nNA beta0_def[10]    0.03    0.00  0.02   -0.02    0.02    0.03   0.05   0.08   909\nNA beta0_def[11]    0.01    0.00  0.03   -0.04   -0.01    0.01   0.03   0.06   995\nNA beta0_def[12]   -0.20    0.00  0.03   -0.27   -0.22   -0.20  -0.17  -0.13   216\nNA beta1_att[1]     0.39    0.01  0.38   -0.38    0.15    0.39   0.63   1.12   972\nNA beta1_att[2]    -0.87    0.01  0.38   -1.64   -1.13   -0.86  -0.62  -0.17  1045\nNA beta1_att[3]     0.32    0.01  0.35   -0.32    0.07    0.30   0.55   1.05   920\nNA beta1_att[4]     0.20    0.01  0.36   -0.47   -0.04    0.20   0.43   0.91   954\nNA beta1_att[5]    -0.17    0.02  0.39   -0.93   -0.42   -0.17   0.07   0.65   673\nNA beta1_att[6]     0.95    0.01  0.35    0.26    0.72    0.96   1.18   1.64   705\nNA beta1_att[7]    -0.54    0.02  0.49   -1.52   -0.88   -0.53  -0.22   0.50   895\nNA beta1_att[8]    -2.14    0.03  0.57   -3.33   -2.52   -2.11  -1.77  -1.10   330\nNA beta1_att[9]     0.79    0.01  0.32    0.15    0.57    0.79   1.02   1.41   939\nNA beta1_att[10]    0.05    0.02  0.42   -0.79   -0.22    0.04   0.34   0.89   768\nNA beta1_att[11]    1.17    0.01  0.36    0.46    0.92    1.17   1.42   1.83   897\nNA beta1_att[12]   -0.16    0.00  0.05   -0.25   -0.19   -0.15  -0.12  -0.06   729\nNA beta1_def[1]     0.12    0.01  0.17   -0.20    0.00    0.11   0.22   0.45   894\nNA beta1_def[2]     0.02    0.00  0.13   -0.24   -0.06    0.03   0.11   0.29   814\nNA beta1_def[3]     0.00    0.00  0.14   -0.27   -0.09    0.01   0.09   0.28   834\nNA beta1_def[4]     0.29    0.01  0.17   -0.06    0.17    0.29   0.40   0.64   317\nNA beta1_def[5]     0.07    0.01  0.17   -0.25   -0.04    0.06   0.18   0.41   466\nNA beta1_def[6]     0.04    0.01  0.17   -0.28   -0.07    0.03   0.15   0.35   990\nNA beta1_def[7]    -0.18    0.01  0.20   -0.60   -0.31   -0.17  -0.05   0.20   479\nNA beta1_def[8]    -0.71    0.02  0.17   -1.01   -0.83   -0.72  -0.61  -0.37    92\nNA beta1_def[9]    -0.07    0.01  0.15   -0.35   -0.18   -0.06   0.03   0.23   866\nNA beta1_def[10]    0.03    0.01  0.14   -0.26   -0.05    0.03   0.13   0.30   696\nNA beta1_def[11]   -0.01    0.01  0.14   -0.29   -0.11   -0.01   0.09   0.28   804\nNA beta1_def[12]    0.40    0.01  0.15    0.11    0.29    0.39   0.49   0.70   194\nNA beta1_ser[1]     0.13    0.02  0.50   -0.80   -0.20    0.12   0.43   1.15   956\nNA beta1_ser[2]     0.49    0.02  0.51   -0.48    0.15    0.46   0.82   1.53   815\nNA beta1_ser[3]     0.72    0.02  0.48   -0.20    0.39    0.71   1.03   1.67   474\nNA beta1_ser[4]    -0.65    0.01  0.43   -1.50   -0.92   -0.64  -0.36   0.20   884\nNA beta1_ser[5]     1.27    0.02  0.44    0.39    0.97    1.26   1.57   2.18   569\nNA beta1_ser[6]    -0.39    0.02  0.61   -1.57   -0.78   -0.42   0.00   0.83   883\nNA beta1_ser[7]    -0.88    0.03  0.60   -2.13   -1.27   -0.87  -0.45   0.24   432\nNA beta1_ser[8]     0.00    0.02  0.54   -1.06   -0.35   -0.01   0.35   1.06   879\nNA beta1_ser[9]    -0.05    0.02  0.47   -0.92   -0.37   -0.07   0.28   0.93   951\nNA beta1_ser[10]   -0.60    0.02  0.49   -1.61   -0.90   -0.58  -0.27   0.37   771\nNA beta1_ser[11]    0.99    0.02  0.52   -0.01    0.63    0.99   1.35   1.99   526\nNA beta1_ser[12]   -1.03    0.02  0.46   -1.99   -1.33   -1.02  -0.71  -0.17   685\nNA beta1_blo[1]    -0.02    0.00  0.09   -0.20   -0.08   -0.02   0.05   0.17   981\nNA beta1_blo[2]    -0.21    0.01  0.12   -0.45   -0.28   -0.20  -0.12   0.00   404\nNA beta1_blo[3]    -0.02    0.00  0.06   -0.14   -0.06   -0.02   0.02   0.10   856\nNA beta1_blo[4]    -0.04    0.00  0.06   -0.17   -0.08   -0.04   0.00   0.08  1037\nNA beta1_blo[5]     0.16    0.00  0.10   -0.02    0.09    0.15   0.23   0.36   586\nNA beta1_blo[6]     0.01    0.00  0.06   -0.10   -0.03    0.01   0.05   0.12  1100\nNA beta1_blo[7]     0.08    0.00  0.07   -0.05    0.04    0.08   0.13   0.23   734\nNA beta1_blo[8]    -0.09    0.00  0.11   -0.30   -0.16   -0.09  -0.01   0.11   922\nNA beta1_blo[9]    -0.15    0.00  0.08   -0.32   -0.21   -0.15  -0.10   0.00   773\nNA beta1_blo[10]   -0.03    0.00  0.05   -0.14   -0.07   -0.03   0.01   0.08   968\nNA beta1_blo[11]   -0.01    0.00  0.09   -0.19   -0.07   -0.01   0.05   0.16   993\nNA beta1_blo[12]    0.31    0.01  0.12    0.09    0.23    0.30   0.39   0.57   263\nNA               Rhat\nNA mu            1.02\nNA home          1.02\nNA gamma[1]      1.05\nNA gamma[2]      1.03\nNA gamma[3]      1.06\nNA delta[1]      1.01\nNA delta[2]      1.01\nNA delta[3]      1.03\nNA delta[4]      1.01\nNA beta0_att[1]  1.00\nNA beta0_att[2]  1.00\nNA beta0_att[3]  1.00\nNA beta0_att[4]  1.00\nNA beta0_att[5]  1.00\nNA beta0_att[6]  1.00\nNA beta0_att[7]  1.00\nNA beta0_att[8]  1.00\nNA beta0_att[9]  1.00\nNA beta0_att[10] 1.00\nNA beta0_att[11] 1.00\nNA beta0_att[12] 1.00\nNA beta0_def[1]  1.00\nNA beta0_def[2]  1.00\nNA beta0_def[3]  1.00\nNA beta0_def[4]  1.00\nNA beta0_def[5]  1.00\nNA beta0_def[6]  1.00\nNA beta0_def[7]  1.00\nNA beta0_def[8]  1.00\nNA beta0_def[9]  1.00\nNA beta0_def[10] 1.00\nNA beta0_def[11] 1.00\nNA beta0_def[12] 1.00\nNA beta1_att[1]  1.00\nNA beta1_att[2]  1.00\nNA beta1_att[3]  1.00\nNA beta1_att[4]  1.00\nNA beta1_att[5]  1.00\nNA beta1_att[6]  1.00\nNA beta1_att[7]  1.00\nNA beta1_att[8]  1.00\nNA beta1_att[9]  1.00\nNA beta1_att[10] 1.00\nNA beta1_att[11] 1.00\nNA beta1_att[12] 1.00\nNA beta1_def[1]  1.00\nNA beta1_def[2]  1.00\nNA beta1_def[3]  1.00\nNA beta1_def[4]  1.01\nNA beta1_def[5]  1.00\nNA beta1_def[6]  1.00\nNA beta1_def[7]  1.01\nNA beta1_def[8]  1.03\nNA beta1_def[9]  1.00\nNA beta1_def[10] 1.00\nNA beta1_def[11] 1.00\nNA beta1_def[12] 1.01\nNA beta1_ser[1]  1.00\nNA beta1_ser[2]  1.00\nNA beta1_ser[3]  1.00\nNA beta1_ser[4]  1.00\nNA beta1_ser[5]  1.01\nNA beta1_ser[6]  1.00\nNA beta1_ser[7]  1.00\nNA beta1_ser[8]  1.00\nNA beta1_ser[9]  1.00\nNA beta1_ser[10] 1.00\nNA beta1_ser[11] 1.01\nNA beta1_ser[12] 1.00\nNA beta1_blo[1]  1.00\nNA beta1_blo[2]  1.00\nNA beta1_blo[3]  1.00\nNA beta1_blo[4]  1.00\nNA beta1_blo[5]  1.00\nNA beta1_blo[6]  1.00\nNA beta1_blo[7]  1.00\nNA beta1_blo[8]  1.00\nNA beta1_blo[9]  1.00\nNA beta1_blo[10] 1.00\nNA beta1_blo[11] 1.00\nNA beta1_blo[12] 1.00\nNA \nNA Samples were drawn using NUTS(diag_e) at Mon Jul 22 14:06:07 2024.\nNA For each parameter, n_eff is a crude measure of effective sample size,\nNA and Rhat is the potential scale reduction factor on split chains (at \nNA convergence, Rhat=1).\n```\n\n\n:::\n:::\n\n\nThe diagnostic results are not perfect, perhaps I should run the algorithm a bit longer to get better results as a total of $1000$ iterations does not seem enough. Here I do not bother to save time. To get an idea about posterior results I can plot at the average marginal mean offensive and defensive skills for each of the $12$ teams in the league using the following code.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#plot att vs def effext by team\nmodel_stan_par<-extract(model_stan)\n\nbeta0.att<-apply(model_stan_par$beta0_att, 2, mean)\nbeta0.def<-apply(model_stan_par$beta0_def, 2, mean)\nnames<-unique(data.frame(data$home.team,data$h)[order(data$h),][,1])\n\nplot(beta0.att,beta0.def, main = \"\", type = \"n\", xlab = \"Mean attack effect\", ylab = \"Mean defence effect\", xlim=c(-0.13,0.08), ylim=c(-0.18,0.1))\npoints(beta0.att,beta0.def, pch=16, col=\"red\",cex = 1.2)\nabline(v=0)\nabline(h=0)\ntext(beta0.att,beta0.def,names,cex = 0.8, adj = c(0.4,1.3))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nDifferent clusters of teams can be easily detected and suggest a different performance of the teams based on their average offensive and defensive skills. Those associated with higher offensive (to the right) and lower defensive (to the bottom) effects are the ones with the best performance across the season.\n\n## MCMC diagnostics\n\nUsing the generated MCMC samples I can now look at some diagnostic measures. For example, we can assess convergence of the chains using the function `mcmc_combo` in the package `bayesplot` which provides a summary of convergence diagnostics using different graphics. We consider the marginal skill parameters for four teams to give an example. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmcmc_combo(model_stan, pars=c(\"beta0_att[1]\",\"beta0_att[2]\",\n                              \"beta0_att[3]\",\"beta0_att[4]\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_combo(model_stan, pars=c(\"beta0_def[1]\",\"beta0_def[2]\",\n                              \"beta0_def[3]\",\"beta0_def[4]\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n:::\n\n\n## Model validation\n\nWe can finally assess the fit of the model to the data by computing posterior predictive checks, where we use the posterior values of the parameters to sample a large number of replications for the data. We then use these to generate different types of results and compare them with the actual results to detect possible misfits of the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#obtain parameters to generate replications\ny1.pred<-y2.pred<-matrix(NA,length(model_stan_par$home),132)\nds.pred<-dg.pred<-matrix(NA,length(model_stan_par$home),132)\npi.s<-pi.g<-matrix(NA,length(model_stan_par$home),132)\ny1.mat<-y2.mat<-ds.mat<-matrix(NA,length(model_stan_par$home),132)\nfor(i in 1:length(model_stan_par$home)){\n y1.mat[i,]<-y1\n y2.mat[i,]<-y2\n ds.mat[i,]<-ds\n pi.s[i,]<-inv.logit(model_stan_par$gamma[i,1] + model_stan_par$gamma[i,2]*y1.mat[i,] + model_stan_par$gamma[i,3]*y2.mat[i,])\n pi.g[i,]<-inv.logit(model_stan_par$delta[i,1] + model_stan_par$delta[i,2]*y1.mat[i,] + model_stan_par$delta[i,3]*y2.mat[i,] + model_stan_par$delta[i,4]*ds.mat[i,])\n}\n\n#generate predictions\nset.seed(3456)\nfor(i in 1:length(model_stan_par$home)){\n  y1.pred[i,]<-rpois(n=132,lambda = model_stan_par$theta1[i,])\n  y2.pred[i,]<-rpois(n=132,lambda = model_stan_par$theta2[i,])\n  ds.pred[i,]<-rbinom(n=132, size = 1,prob = pi.s[i,])\n  dg.pred[i,]<-rbinom(n=132, size = 1,prob = pi.g[i,])\n}\n\n#compute prediction points\nresults<-list()\nfor(i in 1:1000){\n  results[[i]]<-data.frame(y1.pred[i,],y2.pred[i,],ds.pred[i,],dg.pred[i,],data$h,data$a) \n  results[[i]]$points.home<-ifelse(results[[i]]$ds.pred.i...==0 & results[[i]]$dg.pred.i...==1,3,0)\n  results[[i]]$points.home<-ifelse(results[[i]]$ds.pred.i...==1 & results[[i]]$dg.pred.i...==1,2,results[[i]]$points.home)\n  results[[i]]$points.home<-ifelse(results[[i]]$ds.pred.i...==1 & results[[i]]$dg.pred.i...==0,1,results[[i]]$points.home)\n  \n  results[[i]]$points.away<-ifelse(results[[i]]$ds.pred.i...==0 & results[[i]]$dg.pred.i...==0,3,0)\n  results[[i]]$points.away<-ifelse(results[[i]]$ds.pred.i...==1 & results[[i]]$dg.pred.i...==0,2,results[[i]]$points.away)\n  results[[i]]$points.away<-ifelse(results[[i]]$ds.pred.i...==1 & results[[i]]$dg.pred.i...==1,1,results[[i]]$points.away)\n}\n\n#compare results for scores by team\ntot.y1.list<-tot.y2.list<-list()\nfor(i in 1:1000){\n  tot.y1.list[[i]]<-ddply(results[[i]], .(data.h), summarise, totscorehome=sum(y1.pred.i...))\n  tot.y2.list[[i]]<-ddply(results[[i]], .(data.a), summarise, totscoreaway=sum(y2.pred.i...))\n}\ntot.y1.list.neg<-tot.y2.list.neg<-list()\nfor(i in 1:1000){\n  tot.y1.list.neg[[i]]<-ddply(results[[i]], .(data.h), summarise, totscorehomeneg=sum(y2.pred.i...))\n  tot.y2.list.neg[[i]]<-ddply(results[[i]], .(data.a), summarise, totscoreawayneg=sum(y1.pred.i...))\n}\n\n\ntot.y1.list.mat<-tot.y2.list.mat<-matrix(NA,1000,12)\ntot.y1.list.neg.mat<-tot.y2.list.neg.mat<-matrix(NA,1000,12)\nfor(i in 1:1000){\n  tot.y1.list.mat[i,]<-tot.y1.list[[i]][,2]\n  tot.y2.list.mat[i,]<-tot.y2.list[[i]][,2]\n  tot.y1.list.neg.mat[i,]<-tot.y1.list.neg[[i]][,2]\n  tot.y2.list.neg.mat[i,]<-tot.y2.list.neg[[i]][,2]\n}\ntot.y1.obs<-ddply(data, .(h), summarise, totscorehomeobs=sum(y1))\ntot.y2.obs<-ddply(data, .(a), summarise, totscorehomeobs=sum(y2))\ntot.y1.obs.neg<-ddply(data, .(h), summarise, totscorehomeobs=sum(y2))\ntot.y2.obs.neg<-ddply(data, .(a), summarise, totscorehomeobs=sum(y1))\n\n#compute prediction points\nresults<-list()\nfor(i in 1:1000){\n  results[[i]]<-data.frame(y1.pred[i,],y2.pred[i,],ds.pred[i,],dg.pred[i,],data$h,data$a) \n  results[[i]]$points.home<-ifelse(results[[i]]$ds.pred.i...==0 & results[[i]]$dg.pred.i...==1,3,0)\n  results[[i]]$points.home<-ifelse(results[[i]]$ds.pred.i...==1 & results[[i]]$dg.pred.i...==1,2,results[[i]]$points.home)\n  results[[i]]$points.home<-ifelse(results[[i]]$ds.pred.i...==1 & results[[i]]$dg.pred.i...==0,1,results[[i]]$points.home)\n  \n  results[[i]]$points.away<-ifelse(results[[i]]$ds.pred.i...==0 & results[[i]]$dg.pred.i...==0,3,0)\n  results[[i]]$points.away<-ifelse(results[[i]]$ds.pred.i...==1 & results[[i]]$dg.pred.i...==0,2,results[[i]]$points.away)\n  results[[i]]$points.away<-ifelse(results[[i]]$ds.pred.i...==1 & results[[i]]$dg.pred.i...==1,1,results[[i]]$points.away)\n}\n\n#compare results for scores by team\ntot.y1.list<-tot.y2.list<-list()\nfor(i in 1:1000){\n  tot.y1.list[[i]]<-ddply(results[[i]], .(data.h), summarise, totscorehome=sum(y1.pred.i...))\n  tot.y2.list[[i]]<-ddply(results[[i]], .(data.a), summarise, totscoreaway=sum(y2.pred.i...))\n}\ntot.y1.list.neg<-tot.y2.list.neg<-list()\nfor(i in 1:1000){\n  tot.y1.list.neg[[i]]<-ddply(results[[i]], .(data.h), summarise, totscorehomeneg=sum(y2.pred.i...))\n  tot.y2.list.neg[[i]]<-ddply(results[[i]], .(data.a), summarise, totscoreawayneg=sum(y1.pred.i...))\n}\n\n\ntot.y1.list.mat<-tot.y2.list.mat<-matrix(NA,1000,12)\ntot.y1.list.neg.mat<-tot.y2.list.neg.mat<-matrix(NA,1000,12)\nfor(i in 1:1000){\n  tot.y1.list.mat[i,]<-tot.y1.list[[i]][,2]\n  tot.y2.list.mat[i,]<-tot.y2.list[[i]][,2]\n  tot.y1.list.neg.mat[i,]<-tot.y1.list.neg[[i]][,2]\n  tot.y2.list.neg.mat[i,]<-tot.y2.list.neg[[i]][,2]\n}\ntot.y1.obs<-ddply(data, .(h), summarise, totscorehomeobs=sum(y1))\ntot.y2.obs<-ddply(data, .(a), summarise, totscorehomeobs=sum(y2))\ntot.y1.obs.neg<-ddply(data, .(h), summarise, totscorehomeobs=sum(y2))\ntot.y2.obs.neg<-ddply(data, .(a), summarise, totscorehomeobs=sum(y1))\n\n#scored\ntot.y.obs<-tot.y1.obs[,2]+tot.y2.obs[,2]\ntot.y.pred<-apply(tot.y1.list.mat,2,median)+apply(tot.y2.list.mat,2,median)\nres.y<-cbind(tot.y.obs,tot.y.pred)\nrownames(res.y)<-names\nres.y<-round(res.y,digits = 0)\n\n#conceded\ntot.y.obs.neg<-tot.y1.obs.neg[,2]+tot.y2.obs.neg[,2]\ntot.y.pred.neg<-apply(tot.y1.list.neg.mat,2,median)+apply(tot.y2.list.neg.mat,2,median)\nres.y.neg<-cbind(tot.y.obs.neg,tot.y.pred.neg)\nrownames(res.y.neg)<-names\nres.y.neg<-round(res.y.neg,digits = 0)\n\n#compare results for points\ndata.points.list<-list()\nfor(i in 1:1000){\n  data.points.list[[i]]<-data.frame(data$Game)\n  data.points.list[[i]]$Game<-data$Game\n  data.points.list[[i]]$h<-data$h\n  data.points.list[[i]]$a<-data$a\n  data.points.list[[i]]$points.home<-results[[i]]$points.home\n  data.points.list[[i]]$points.away<-results[[i]]$points.away\n}\ntot.home.list<-tot.away.list<-tot.team.list<-list()\nfor(i in 1:1000){\n  tot.home.list[[i]]<-ddply(data.points.list[[i]], .(h), summarise, totpointhome=sum(points.home))\n  tot.away.list[[i]]<-ddply(data.points.list[[i]], .(a), summarise, totpointaway=sum(points.away))\n}\n\nfor(i in 1:1000){\n  tot.team.list[[i]]<-data.frame(levels(data$home.team), tot.home.list[[i]]$h)\n  tot.team.list[[i]]$tot.team<-tot.home.list[[i]]$totpointhome + tot.away.list[[i]]$totpointaway\n  tot.team.list[[i]]$true.team<-c(19, 39, 23, 50, 19, 11, 37, 51, 32, 33, 27, 50)\n  tot.team.list[[i]]<-tot.team.list[[i]][order(tot.team.list[[i]]$tot.team, decreasing = TRUE),]\n  tot.team.list[[i]]$rank<-rep(1:12)\n}\n\n#plot total scores by team\ntot.scores<-matrix(NA,1000,12)\ncolnames(tot.scores)<-names\nfor(i in 1:1000){\n  for(j in 1:12){\n    tot.scores[i,j]<-tot.team.list[[i]]$tot.team[tot.team.list[[i]]$tot.home.list..i...h==j] \n  }\n}\ntot.scores.obs<-c(19, 39, 23, 50, 19, 11, 37, 51, 32, 33, 27, 50)\ntot.scores.med<-apply(tot.scores, 2, median)\ntot.scores.final<-cbind(tot.scores.obs,tot.scores.med)\n\n#plot total wins \ntot.wins<-matrix(NA,1000,12)\ncolnames(tot.wins)<-names\nfor(i in 1:1000){\n  for(j in 1:12){\n    tot.wins[i,j]<-length(data.points.list[[i]]$points.home[data.points.list[[i]]$points.home>1 & \n                                                              data.points.list[[i]]$h==j]) + length(data.points.list[[i]]$points.away[data.points.list[[i]]$points.away>1 & \n                                                                                                                                        data.points.list[[i]]$a==j])\n  }\n}\ntot.wins.obs<-c(7,12,6,17,7,5,13,17,10,12,8,18)\ntot.wins.prop<-tot.wins/22\ntot.wins.obs.prop<-tot.wins.obs/22\ntot.wins.med<-apply(tot.wins, 2, median)\ntot.wins.final<-cbind(tot.wins.obs,tot.wins.med)\n```\n:::\n\n\nHere, for each team, we compare the predicted and observed total number of points scored in the matches, the number of won/lost matches, and the league points scored based on a replicated and the original season results. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#summarise pred results\nres.final.obs<-cbind(res.y[,1],res.y.neg[,1],tot.wins.final[,1],tot.scores.final[,1])\nres.final.pred<-cbind(res.y[,2],res.y.neg[,2],tot.wins.final[,2],tot.scores.final[,2])\nres.final<-cbind(res.final.obs,res.final.pred)\ncolnames(res.final)<-c(\"scored\",\"conc'd\",\"wins\",\"points\",\"scored\",\"conc'd\",\"wins\",\"points\")\nknitr::kable(res.final, \"pandoc\", align = \"c\")\n```\n\n::: {.cell-output-display}\n\n                 scored    conc'd    wins    points    scored    conc'd    wins    points \n--------------  --------  --------  ------  --------  --------  --------  ------  --------\nBergamo           1848      2025      7        19       1846      2019      7        20   \nBusto Arsizio     1999      1927      12       39       1996      1918      12       37   \nCasalmaggiore     1922      2051      6        23       1914      2035      7        23   \nConegliano        1960      1696      17       50       1958      1704      18       50   \nFilottrano        1781      1961      7        19       1799      1955      6        18   \nLegnano           1642      1903      5        11       1662      1902      4        17   \nMonza             2003      1943      13       37       1999      1936      13       38   \nNovara            1987      1776      17       51       1954      1774      17       51   \nPesaro            1776      1820      10       32       1786      1823      11       33   \nPiacenza          1888      1939      12       33       1887      1934      9        30   \nSan Casciano      1807      1881      8        27       1808      1878      9        29   \nScandicci         1865      1556      18       50       1862      1583      18       51   \n\n\n:::\n:::\n\n\nPredicted results (the last four columns in the table) are not so bad, especially when looking at the number of league points scored by the teams between the replicated and observed season which are quite similar. These results suggest that the model seems to predict in a reasonable way the league results. To further assess this aspect, we consider two plots. The first compares the ranking of the teams across a large number of replications of the season based on the number of wins, losses and league points gained for each team.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#summarise pred results\nres.matrix<-matrix(NA,length(tot.team.list),12)\ncolnames(res.matrix)<-names\nfor(i in 1:1000){\n  res.matrix[i,1]<-tot.team.list[[i]]$rank[tot.team.list[[i]]$tot.home.list..i...h==1]\n  res.matrix[i,2]<-tot.team.list[[i]]$rank[tot.team.list[[i]]$tot.home.list..i...h==2]\n  res.matrix[i,3]<-tot.team.list[[i]]$rank[tot.team.list[[i]]$tot.home.list..i...h==3]\n  res.matrix[i,4]<-tot.team.list[[i]]$rank[tot.team.list[[i]]$tot.home.list..i...h==4]\n  res.matrix[i,5]<-tot.team.list[[i]]$rank[tot.team.list[[i]]$tot.home.list..i...h==5]\n  res.matrix[i,6]<-tot.team.list[[i]]$rank[tot.team.list[[i]]$tot.home.list..i...h==6]\n  res.matrix[i,7]<-tot.team.list[[i]]$rank[tot.team.list[[i]]$tot.home.list..i...h==7]\n  res.matrix[i,8]<-tot.team.list[[i]]$rank[tot.team.list[[i]]$tot.home.list..i...h==8]\n  res.matrix[i,9]<-tot.team.list[[i]]$rank[tot.team.list[[i]]$tot.home.list..i...h==9]\n  res.matrix[i,10]<-tot.team.list[[i]]$rank[tot.team.list[[i]]$tot.home.list..i...h==10]\n  res.matrix[i,11]<-tot.team.list[[i]]$rank[tot.team.list[[i]]$tot.home.list..i...h==11]\n  res.matrix[i,12]<-tot.team.list[[i]]$rank[tot.team.list[[i]]$tot.home.list..i...h==12]\n}\n\n#create stacked barplot of results\ndata.barplot<-data.frame(rep(1:c(1000*12)))\nnames(data.barplot)<-c(\"Game\")\ndata.barplot$position<-as.factor(c(res.matrix[,1],res.matrix[,2],res.matrix[,3],res.matrix[,4],\n                                   res.matrix[,5],res.matrix[,6],res.matrix[,7],res.matrix[,8],\n                                   res.matrix[,9],res.matrix[,10],res.matrix[,11],res.matrix[,12]))\ndata.barplot$team<-rep(NA,1000*12)\ndata.barplot$team[1:1000]<-rep(paste(names[1]),1000)\ndata.barplot$team[1001:2000]<-rep(paste(names[2]),1000)\ndata.barplot$team[2001:3000]<-rep(paste(names[3]),1000)\ndata.barplot$team[3001:4000]<-rep(paste(names[4]),1000)\ndata.barplot$team[4001:5000]<-rep(paste(names[5]),1000)\ndata.barplot$team[5001:6000]<-rep(paste(names[6]),1000)\ndata.barplot$team[6001:7000]<-rep(paste(names[7]),1000)\ndata.barplot$team[7001:8000]<-rep(paste(names[8]),1000)\ndata.barplot$team[8001:9000]<-rep(paste(names[9]),1000)\ndata.barplot$team[9001:10000]<-rep(paste(names[10]),1000)\ndata.barplot$team[10001:11000]<-rep(paste(names[11]),1000)\ndata.barplot$team[11001:12000]<-rep(paste(names[12]),1000)\n#data.barplot$team<-as.factor(data.barplot$team)\ndata.barplot$team <-factor(data.barplot$team, levels = c(\"Novara\", \"Scandicci\",\"Conegliano\", \"Monza\",\"Busto Arsizio\",\n                                                         \"Pesaro\",\"Piacenza\", \"San Casciano\",\"Casalmaggiore\", \"Bergamo\",\n                                                         \"Filottrano\", \"Legnano\"))\n\n\n\ndata.barplot$match<-c(rep(1,1000),rep(2,1000),rep(3,1000),rep(4,1000),rep(5,1000),rep(6,1000),\n                      rep(7,1000),rep(8,1000),rep(9,1000),rep(10,1000),rep(11,1000),rep(12,1000))\ndata.barplot$match<-as.factor(data.barplot$match)\ndata.barplot$Game<-rep(1,nrow(data.barplot))\ndata.barplot$area<-ifelse(data.barplot$position==1|data.barplot$position==2|data.barplot$position==3,\"high\",\"middle\")\ndata.barplot$area<-ifelse(data.barplot$position==12|data.barplot$position==11|data.barplot$position==10,\"low\",data.barplot$area)\ndata.barplot$area<-as.factor(data.barplot$area)\ndata.barplot$area<-ordered(data.barplot$area,levels=c(\"low\",\"middle\",\"high\"))\ndata.barplot$team<-factor(data.barplot$team,levels = rev(levels(data.barplot$team)))\n\ndf.summary1<-ddply(data.barplot,.(team,position),summarise,count=sum(Game), percent=sum(Game)/1000)\ndf.summary2<-ddply(data.barplot,.(team,area),summarise,count=sum(Game), percent=sum(Game)/1000)\n\nggplot(df.summary1, aes(x=team, y=percent, fill=position)) +\n  geom_bar(stat=\"identity\", width = 0.7, colour=\"black\", lwd=0.1) +\n  geom_text(aes(label=ifelse(percent >= 0.1, paste0(sprintf(\"%.0f\", percent*100),\"%\"),\"\")),\n            position=position_stack(vjust=0.5), colour=\"white\") +\n  coord_flip() + scale_y_continuous(labels = percent_format()) +\n  labs(y=\"\", x=\"\") + scale_fill_viridis(discrete = T) + \n  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_rect(fill = \"white\"),\n        axis.line = element_line(colour = \"black\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nThe mean rankings of the teams are in line with those observed in the actual season, while also providing uncertainty about the chance of each team to end in a particular position in the league (only percentages above $10\\%$ are shown for clarity).\n\nThe second plot compares the points trend throughout the season for each team with respect to the trend predicted by the model based on the replicated results for each match in the season.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#########plot for cumlative points over simulated season\npoints.list<-cum.points.list<-list()\nfor(i in 1:nrow(res.matrix)){\n  points.list[[i]]<-matrix(NA,22,12)\n  cum.points.list[[i]]<-matrix(NA,22,12)\n  for(j in 1:12){\n    points.list[[i]][,j]<-c(data.points.list[[i]]$points.home[data.points.list[[i]]$h==j],data.points.list[[i]]$points.away[data.points.list[[i]]$a==j])\n  }\n  colnames(points.list[[i]])<-unique(levels(data$home.team))\n  rownames(points.list[[i]])<-rep(1:22)\n  cum.points.list[[i]]<-apply(points.list[[i]], 2, cumsum)\n}\n\n#########plot for cumlative points over simulated season\npoints.list<-cum.points.list<-list()\nfor(i in 1:nrow(res.matrix)){\n  points.list[[i]]<-matrix(NA,22,12)\n  cum.points.list[[i]]<-matrix(NA,22,12)\n  for(j in 1:12){\n    points.list[[i]][,j]<-c(data.points.list[[i]]$points.home[data.points.list[[i]]$h==j],data.points.list[[i]]$points.away[data.points.list[[i]]$a==j])\n  }\n  colnames(points.list[[i]])<-unique(levels(data$home.team))\n  rownames(points.list[[i]])<-rep(1:22)\n  cum.points.list[[i]]<-apply(points.list[[i]], 2, cumsum)\n}\n\n#plot cumulative points obs vs pred\nobs.cum.points<-matrix(NA,22,12)\ncolnames(obs.cum.points)<-unique(levels(data$home.team))\nrownames(obs.cum.points)<-rep(1:22)\nobs.cum.points[1,]<-c(0,1,0,3,3,3,0,2,0,0,3,3)\nobs.cum.points[2,]<-c(0,3,0,3,0,0,3,3,0,3,0,3)\nobs.cum.points[3,]<-c(0,2,3,3,0,0,0,3,3,1,0,3)\nobs.cum.points[4,]<-c(0,3,0,3,0,0,3,3,1,2,0,3)\nobs.cum.points[5,]<-c(0,3,0,3,0,3,0,3,3,0,0,3)\nobs.cum.points[6,]<-c(0,3,1,3,0,0,0,3,1,3,2,2)\nobs.cum.points[7,]<-c(2,1,3,2,0,1,1,3,2,2,1,0)\nobs.cum.points[8,]<-c(0,2,1,1,0,0,3,2,3,2,1,3)\nobs.cum.points[9,]<-c(3,3,1,3,0,2,2,1,0,0,3,0)\nobs.cum.points[10,]<-c(1,2,1,2,1,2,1,1,2,2,1,2)\nobs.cum.points[11,]<-c(0,1,0,3,0,0,3,3,0,3,3,2)\nobs.cum.points[12,]<-c(3,0,0,3,0,0,3,3,3,0,0,3)\nobs.cum.points[13,]<-c(0,1,3,3,2,0,3,2,1,3,0,0)\nobs.cum.points[14,]<-c(2,3,1,3,0,0,0,3,3,0,0,3)\nobs.cum.points[15,]<-c(2,1,0,3,2,0,3,1,0,3,0,3)\nobs.cum.points[16,]<-c(0,3,0,3,0,0,0,3,3,0,3,3)\nobs.cum.points[17,]<-c(2,0,3,0,0,3,3,1,0,3,0,3)\nobs.cum.points[18,]<-c(0,0,0,3,3,1,2,3,1,2,3,0)\nobs.cum.points[19,]<-c(3,3,3,2,0,0,3,0,0,1,0,3)\nobs.cum.points[20,]<-c(0,0,2,0,3,1,0,3,3,0,3,3)\nobs.cum.points[21,]<-c(0,3,0,1,3,0,2,2,0,1,3,3)\nobs.cum.points[22,]<-c(1,1,1,0,2,0,2,3,3,2,1,2)\n\nobs.cum.points<-apply(obs.cum.points, 2, cumsum)\n\npar(mar=c(2.1, 3.1, 3.1, 3.1))\npar(mfrow=c(4,3), mai = c(0.4, 0.4, 0.1, 0.2))\nfor(i in 1:12){\n  plot(rep(1:22),obs.cum.points[,i], axes = F, type = \"n\", xlab = \"games\", ylab = \"points\",xlim = c(0,23),ylim = c(0,54))\n  axis(1,at=c(0,5,10,15,20,25),labels = c(0,5,10,15,20,25))\n  axis(2,at=c(0,10,20,30,40,50),labels = c(0,10,20,30,40,50))\n  lines(rep(1:22),obs.cum.points[,i], lty=1,lwd=1,col=\"black\")\n  lines(rep(1:22), cum.points.list[[7]][,i], lty=1,lwd=1,col=\"red\")\n  text(5,50,unique(levels(names))[i],pos = 1, cex = 1)\n}\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nThe observed trends (black lines) are pretty much matched by the trends predicted by the model (red lines) for most of the teams with few exceptions. This suggests that, although the model seems to have a good predictive ability, in some cases there are still margins of improvement. In my original paper I have improved the model using a different parameterisation where I tried to account for the dependence between the latent skill parameters using a scaled inverse Wishart distribution for the covariance matrix of the random effects. Here I do not consider this model here, which lead to some improvements compared with the basic Poisson model.\n\n# Conclusions\n\nOne potential limitation of the framework is that only match-specific statistics are\nused for estimation and prediction purposes. Ideally, the use of set-specific statistics could improve the predictive power of the model. However, this would introduce additional problems related to the choice of the distributions for modelling the number of points scored by the opposing teams in a set, which is subject to specific constraints. Finally, the flexibility of the proposed framework allows the extension of the model in many ways. For example, additional types of in-game statistics (e.g. number of passes), if available, could be incorporated to further improve the predictions of the model; alternative distributions could also be specified to model the total number of scores $y$ during the season (e.g. Negative Binomial) which may result in a better fit to the data.\n\n# References\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}