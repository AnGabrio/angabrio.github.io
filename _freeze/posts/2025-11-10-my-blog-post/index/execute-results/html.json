{
  "hash": "7e830cc941367d40a3a5acfbe2745e05",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Conducting trial-based cost-effectiveness analyses:\"\nsubtitle: \"A tutorial - II\"\ndescription: \"\"\nauthor:\n  - name: Andrea Gabrio\n    url: https://angabrio.github.io/agabriosite2/\n    orcid: 0000-0002-7650-4534\n    affiliation: Maastricht University\n    affiliation-url: https://www.maastrichtuniversity.nl/research/methodology-and-statistics\ndate: 2025-11-10\ncategories: [Quarto, R, Academia, HTA, Cost-Effectiveness, Tutorial] # self-defined categories\n#citation: \n#  url: https://samanthacsik.github.io/posts/2022-10-24-my-blog-post/ \nimage: featured.png\nbibliography: references.bib\ndraft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!\n---\n\nHello dear readers, and welcome back to my blog as usual. Today I would like to provide a quick update as I am in the middle of my heavy teaching period and therefore I do not have much time to write extensive stuff here, my apologies. Mainly a couple of updates:\n\n  1. Last month I attended the [Bayes Conference 2025](https://www.bayes-pharma.org/bayes-2025/), where I presented my latest work related to handling missing data in trial-based CEA with a focus on how to specify Bayesian models to handle missing healthcare resource use. The work has also been recently published on MDM and, if you are interested, you arr welcome to have a free look at it [here](https://journals.sagepub.com/doi/full/10.1177/0272989X251376026). As for the conference, I found it really interesting as it has a heavy focus on pharmaceutical and consultancy companies interests and topics, mostly related to satisfying requirements of regulatory HTA bodies for the submission of HTA assessments or related statistical analyses. Many important statisticians in the field were also present there, either working in academia or in the industry, who brought up a series of interesting theoretical and practical matters related to statistical analyses of clinical and health data. Unfortunately for me, my session was not particularly attractive to this audience as my focus was specifically on trial-based analyses for which, especially pharmas, there is not much of an interest. Regardless I am happy that I was able to join the conference after a long absence (I think since 2015!) and see how things have evolved and how big of an event it has now become. \n  \n  2. Right before leaving for the conference I had the pleasure to give a presentation about trial-based CEA and the importance of using adequate statistical methods in these analyses for the [Health Services Research](https://www.maastrichtuniversity.nl/research/health-services-research) department here at UM. I have collaborated on a series of projects with a few people from this department in the last years, mostly related to the analyses of HTA data, and I have been asked to provide a sort of workshop to PhD students and interested analysts on key analysis methods for trial-based CEAs and how to implement them in `R`. The workshop went well, although I did not manage to cover all topics I intended, as the people present were really interested in the topic and asked a few questions on what they would like to see in a future session. I have provided all material discussed in the last workshop on my [GitHub repository](https://github.com/AnGabrio/Code/tree/master/RHTAmethods) to allow people to play around with the examples, slides, `R` scripts and functions I created to illustrate how different statistical issues typical of CEA data may be handled in practice. I really hope this was helpful for them. Given the interest in the topic, we have decided to double down and give a second workshop this month on another requested topics, namely conducting HTA using decision-based models. I plan to have a similar session to the last one, perhaps with a little more emphasis on the coding aspect since I noted that all attendees last time had their laptops with them and seemed somewhat familiar with `R`.\n\nApart from the previous news, I would also like to provide an update to the code I shared on my last post with respect to the analyses of trial-based CEA data. In particular, due to limited time, last time I provided examples on implementing a series of alternative methods to handle issues such as skewness, correlation, clustering and missing data. One aspect that I skipped at the end was specifically on how to combine missing data methods, namely multiple imputation, with non-parametric bootstrapping approaches for the generation of bootstrap samples that can be used to quantify the level of uncertainty around CE quantities while also appropriately taking into account missingness uncertainty. So, to fill in this gap, today I wanted to complete the code and include a function that can be used to combine the two methods, something that is usually needed when conducting the analyses in practice.\n\n# Combine MI and bootstrapping in CEA\n\nThe following (folded) code is a copy of what I used in my last post to generate some artificial CEA data for exemplary purposes to demonstrate how MICE and non-parametric bootstrapping may be combined in `R`. If not of interest, you may skip the folded code and jump to the actual implementation code in the next section. In this simulation I will make things easy and generate data assuming normal distributions and limited number of covariate data. However, the implementation of the methods shown in the following sections is general and can be applied to more realistic data too.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n#simulate data and missing under different mechanisms\n#set rng for reproducibility\nset.seed(2345)\n#set up parameter values to generate data\nn_full <- 250\nmu_x1 <- 0.5\nsd_x1 <- 0.15\nx1_data <- rnorm(n_full, mu_x1, sd_x1) #simulate covariate values\nn_full <- 250\nmu_x2 <- 100\nsd_x2 <- 25\nx2_data <- rnorm(n_full, mu_x2, sd_x2) #simulate covariate values\np_trt <- 0.5\ntrt_data <- rbinom(n_full, p_trt, size = 1)#simulate trt indicator\nbeta0_data <- 0.2\nbeta1_data <- 0.15\nbeta2_data <- 1\n#simulate outcome values\ny1_data <- beta0_data + beta1_data*trt_data + beta2_data*x1_data + rnorm(n_full, 0, 0.1)\nalpha0_data <- 250\nalpha1_data <- 35\nalpha2_data <- 1\nalpha3_data <- 55\n#simulate outcome values\ny2_data <- alpha0_data + alpha1_data*trt_data + alpha2_data*x2_data + alpha3_data*y1_data + rnorm(n_full, 0, 50)\n#generate fully-observed datset and assign names to variables\nfull.df <- data.frame(y1_data,y2_data,trt_data,x1_data,x2_data)\nnames(full.df) <- c(\"QALY\",\"TC\",\"trt\",\"u\",\"c\")\nfull.df$trt <- ifelse(full.df$trt==0,\"old\",\"new\")\nfull.df$trt <- factor(full.df$trt, levels = c(\"old\",\"new\"))\n\n#introduce MAR missingness in QALY given u\nlibrary(boot)\n#set rng for reproducibility\nset.seed(2345)\n#set parameter values for mechanisms\neta0_mar <- -9\neta_1_mar <- 14.5\neta_2_mar <- 0\neta_3_mar <- 0\np_mar_e <- inv.logit(eta0_mar + eta_1_mar*full.df$u + eta_2_mar*full.df$QALY + eta_3_mar*as.numeric(full.df$trt))\niota0_mar <- -4\niota_1_mar <- 3\niota_2_mar <- 0\niota_3_mar <- 0\np_mar_c <- inv.logit(iota0_mar + iota_1_mar*full.df$c/100 + iota_2_mar*full.df$TC + iota_3_mar*as.numeric(full.df$trt))\n#generate missing data indicators (0=observed,1=missing)\nm_mar_e <- rbinom(n_full, p_mar_e, size = 1)\nm_mar_c <- rbinom(n_full, p_mar_c, size = 1)\nfull.mar <- full.df\n#introduce MAR missing QALY data and distinguish between a variable showing only the observed QALY values (QALY_obs) and another showing only the missing QALY values (QALY_mis)\nfull.mar$m_QALY <- m_mar_e\nfull.mar$m_TC <- m_mar_c\nfull.mar$QALY_obs <- ifelse(full.mar$m_QALY==0,full.mar$QALY,NA)\nfull.mar$TC_obs <- ifelse(full.mar$m_TC==0,full.mar$TC,NA)\n\n#randomly shuffle rows of the MAR dataset\nfull.mar <- full.mar[sample(1:nrow(full.mar)), ]\n#keep only relevant variables and rename them\ndataset.mis <- full.mar[,c(\"QALY_obs\",\"TC_obs\",\"trt\",\"u\",\"c\")]\nnames(dataset.mis) <- c(\"QALY\",\"TC\",\"trt\",\"u\",\"c\")\n```\n:::\n\n\nWe can inspect the first few rows of the generated data stored in the `R` object `full.mar` to see the variable showing the observed QALY values (`QALY`) and TC values (`TC`), which were generated under a MAR mechanism conditional on the fully observed baseline utilities (`u`) and costs (`c`).\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nhead(dataset.mis, n=8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         QALY       TC trt         u         c\n34  0.6891580 378.6541 new 0.3518463  91.95314\n48  0.8021310       NA new 0.5254678  93.04074\n193 0.4477710 455.1781 new 0.2485247 126.63579\n188 0.8710712 471.2896 new 0.4307028 110.27430\n58  0.7926060       NA new 0.4134793 103.14698\n87         NA 458.9715 new 0.6311773 114.55390\n135 0.6656135 423.3912 new 0.3820836 132.51559\n107 0.6320513 320.8635 new 0.3455197 116.77745\n```\n\n\n:::\n:::\n\n\nHere, I will skip descriptions and presentations of MI and bootstrapping as these were given in my previous post, so I will assume that readers will already be familiar with these methods and what they do. If you are not sure, check my previous post for a refresher. \n\nFirst, I will use the following  `R` code to implement MICE (under a MAR assumption) to the generated data. The following MI specification is used: number of imputations $M=5$; PMM as imputation method for all missing variables (`QALY` and `TC`) using corresponding observed baseline values (`u` and `c`) as the only variables included in their respective imputation models.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nlibrary(mice) #load package to implement MICE\n#split data by treatment group (Old and New)\ndataset.mis_Old <- dataset.mis[dataset.mis$trt==\"old\",]\ndataset.mis_New <- dataset.mis[dataset.mis$trt==\"new\",]\n#set up MICE inputs for old group\nmice_Old <- mice(dataset.mis_Old, print = FALSE, method = 'pmm', maxit = 0)\npM_Old <- mice_Old$predictorMatrix #extract default predictor matrix\n#customise pred matrix to your needs (row=variable to be imputed, column=variable used as predictor)\n#in the matrix an entry of 1 means that the corresponding column variable is used as predictor for the corresponding row variable\npM_Old[\"QALY\",c(\"TC\",\"u\")] <- 1 #require that QALY always imputed using TC and u\npM_Old[\"QALY\",c(\"c\")] <- 0 #require that QALY is never imputed using c\npM_Old[\"TC\",c(\"u\")] <- 0 #require that TC is never imputed using u\npM_Old[,c(\"trt\")] <- 0 #require that any variable is never imputed using trt\nmeth_Old <- mice_Old$method #extract default imputation methods\n#by default PMM assumed as imputation methods for numeric variables\n#set up MICE inputs for new group\nmice_New <- mice(dataset.mis_New, print = FALSE, method = 'pmm', maxit = 0)\npM_New <- mice_New$predictorMatrix #extract default predictor matrix\npM_New[\"QALY\",c(\"TC\",\"u\")] <- 1 #require that QALY always imputed using TC and u\npM_New[\"QALY\",c(\"c\")] <- 0 #require that QALY is never imputed using c\npM_New[\"TC\",c(\"u\")] <- 0 #require that TC is never imputed using u\npM_New[,c(\"trt\")] <- 0 #require that any variable is never imputed using trt\nmeth_New <- mice_New$method #extract default imputation methods\nM <- 5 #number of imputations\n#set rng for reproducibility\nset.seed(2345)\n#implement MICE to old and new group\nmice_Old_fit <- mice(dataset.mis_Old, predictorMatrix = pM_Old, method=meth_Old, m = M, print = FALSE)\nmice_New_fit <- mice(dataset.mis_New, predictorMatrix = pM_New, method=meth_New, m = M, print = FALSE)\n#combine the imputed datasets across groups\nmice_fit <- rbind(mice_Old_fit, mice_New_fit)\n```\n:::\n\n\nNext, rather then simply fitting the analysis model to each imputed data sets and summarise the output, as it would be the normal approach from statistical analyses, it is necessary to specify how the bootstrapping technique should be combined with MICE in order to generate bootstrapped and multiply-imputed estimates for the CE quantities of interest, i.e. mean incrementals for QLAYs and Total costs between groups. As I briefly mention at the end of my last post, combination of MI with bootstrapping or other non-standard analysis methods can be very challenging and clear guidelines about the performance of the methods when combined together is still lacking [@schomaker2018bootstrap;@brand2019combining]. In particular, two main distinct combination strategies may be considered:\n\n  1. **Multiple Imputation for the inner loop) \\& Bootstrapping for the outer loop** (MB). The general idea behind this strategy is to first apply MI to the original data set to generate $M$ replications of the imputed data set; then non-parametric bootstrapping is applied to each of these $M$ data sets to generate $B$ bootstrap replications for each of the multiply-imputed data sets, thus producing a total of $M\\times B$ different data sets. Next, the analysis model of interest is fitted to each of these data sets and associated $M\\times B$ estimates for the parameters of interest are derived.\n  \n  2. **Multiple Imputation for the outer loop) \\& Bootstrapping for the inner loop** (BM). The general idea behind this strategy is to first apply non-parametric bootstrapping to the original data set to generate $B$ bootstrap replications of the original data set (including missing values); then MI is applied to each of these $B$ data sets to generate $M$ multiply-imputed data sets for each of the bootstrapped data sets, thus producing a total of $B\\times M$ different data sets. Next, the analysis model of interest is fitted to each of these data sets and associated $B\\times M$ estimates for the parameters of interest are derived.\n\nRegardless of the strategy used to combine MI and bootstrapping, it is then necessary to decide how to summarise the relevant parameter estimates after $M \\times B$ replications have been produced. Also here different approaches have been considered. One option would be to use the entire $M \\times B$ set of parameter estimate replications in order to quantify the level of uncertainty around them. This means that the entire distribution is used to generate standard CE output, such as CE plane and CEAC and related CE quantities with associated intervals. A second option would be to first average parameter estimates across the $M$ multiply-imputed replications in order to obtain a distribution of $B$ estimates, which would then represent the values to be used for generating the CE output. \n\nAlthough the relative performance of these approaches have been examined under some simulation scenarios, where no large differences across these methods have been detected, their actual performance under general situations still needs to be fully assessed. Thus, no general guidelines exist that can recommend one approach over the other in all cases, especially given that these results are based on simulation methods. As a practical guideline, it may be important to outline that *BM* can be computationally much more intensive to implement with respect to *MB*, since the number of bootstrap iterations is typically required to be much higher compared to the number of imputations.\n\nThe following (folded) code part shows how to construct a function which allows the implementation of either MB or BM strategies in the context of trial-based CEA when fitting either a OLS or SUR as the main analysis model for CE data. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n#function and needed packages to generate bootstrap estimates for mean QALY/TC and incremental\n#differences when running a OLS/SUR model after applying MICE to handle missing data\n#note: different ways to combine MI and bootstrapping estimates can be obtained based on the inputs provided\nlibrary(systemfit)\nlibrary(data.table)\nlibrary(rlang)\nlibrary(bootstrap)\nlibrary(emmeans)\nlibrary(mice)\nboot_mi_ec <- function(x, B, QALYreg, TCreg, method = \"OLS\", \n                       profile_QALY=\"default\", profile_TC=\"default\", \n                       trt_pos = 2, combine=\"MB\"){\n  #the following lines are needed to make sure proper inputs are given\n  if(!inherits(x, c(\"mids\"))) {stop(\"Only objects of class 'mids' can be used\")}\n  if(!is.data.frame(x$data)){stop(\"data needs to be a data frame object\")}\n  if(!is.numeric(B)){stop(\"please provide number of bootstrap iterations\")}\n  if(B<=0 | !B%%1==0){stop(\"please provide number of bootstrap iterations\")}\n  if(!is_formula(QALYreg)){stop(\"please provide formula for QALY model\")}\n  if(!is_formula(TCreg)){stop(\"please provide formula for TC model\")}\n  if(!method %in% c(\"OLS\",\"SUR\")){stop(\"please provide valid method name\")}\n  if(!combine %in% c(\"MB\",\"BM\")){stop(\"please provide valid combination name\")}\n  if(!is.numeric(trt_pos) | length(trt_pos)!=1 | trt_pos<=0){stop(\"please provide valid trt indicator position in regressions\")}\n  data <- x$data #original data set\n  n <- dim(data)[1] #original sample size\n  #n covariates \n  nX_e <- dim(model.matrix(QALYreg, data))[2]\n  nX_c <- dim(model.matrix(TCreg, data))[2]\n  #extract name of trt indicator and outcomes from provided formula\n  trt_name_e <- all.vars(QALYreg)[trt_pos]\n  trt_name_c <- all.vars(TCreg)[trt_pos]\n  if(trt_name_e != trt_name_c){stop(\"please provide same trt variable name and position in QALY and TC formuale\")}\n  QALY_name <- all.vars(QALYreg)[1]\n  TC_name <- all.vars(TCreg)[1]\n  #check if trt indicator is factor and store its levels\n  if(is.factor(data[,trt_name_e])){\n    trt_fact <- TRUE\n    trt_lev <- levels(data[,trt_name_e])} else {\n      trt_fact <- FALSE\n      trt_lev <- unique(data[,trt_name_e])}\n  if(length(trt_lev)!=2){stop(\"The function only allows comparison between two trt groups\")}  \n  #check that correct profile provided or set default\n  if(profile_QALY != \"default\"){\n    if(!is.vector(profile_QALY) | length(profile_QALY)!=nX_e){stop(\"provide valid profile for QALYreg\")}}\n  if(profile_TC != \"default\"){\n    if(!is.vector(profile_TC) | length(profile_TC)!=nX_c){stop(\"provide valid profile for TCreg\")}}\n  #extract MI infor from input object\n  M <- x$m #n imputations\n  pm <- x$predictorMatrix #predictor matrix\n  #remove trt as predictor\n  pm[,trt_name_e] <- 0\n  #pm <- pm[-which(colnames(pm)==trt_name_e),-which(colnames(pm)==trt_name_e)]\n  meth <- x$method #imputation methods\n  niter <- x$iteration #n iterations before sampling\n  #split original data by treatment group \n  x_trt1 <- data.frame(x$data[x$data[,trt_name_e]==unique(data[,trt_name_e])[1],])\n  x_trt2 <- data.frame(x$data[x$data[,trt_name_e]==unique(data[,trt_name_e])[2],])\n  #generate imputations and bootstrap estimates based on inputs\n  if(combine == \"MB\"){ #outer loop=MI + inner loop=Boot\n    #prepare empty objects to contain bootstrapped estimates\n    data_MB_list <- list()\n    coeff_c <- coeff_e <- matrix(NA, nrow = M, ncol = B)\n    em_c_ctr <- em_e_ctr <- matrix(NA, nrow = M, ncol = B)\n    em_c_int <- em_e_int <- matrix(NA, nrow = M, ncol = B)\n    data_imp <- list()\n    for(m in 1:M){\n      #apply MI to each arm based on arguments from mice objects provided as input\n      mice_data_trt1 <- mice(x_trt1, predictorMatrix = pm, \n        method=meth,m = M, maxit = niter, print = FALSE)\n      mice_data_trt2 <- mice(x_trt2, predictorMatrix = pm, \n        method=meth,m = M, maxit = niter, print = FALSE)\n      #combine the imputed datasets across groups\n      data_imp <- rbind(mice_data_trt1, mice_data_trt2)\n      #extract imputed data sets\n      data_imp[[m]] <- data.table(complete(data_imp,m))\n      for(i in 1:B){\n        #sample with replacement for each imputed data set\n        data_MB_list[[i]] <- data_imp[[m]][sample(.N, n, replace = T)]\n        #fit model\n        model_MB_ec <- systemfit(list(QALYreg = QALYreg, TCreg = TCreg), \n                              method=method, data=data_MB_list[[i]])        \n        #extract covariate values\n        X_e <- model.matrix(model_MB_ec$eq[[1]])\n        X_c <- model.matrix(model_MB_ec$eq[[2]])        \n        #define QALYreg profile\n        if(profile_QALY == \"default\"){\n          profile_b_QALY <- apply(X_e, 2, mean, na.rm=T)\n        } else {profile_b_QALY <- profile_QALY}\n        profile_b_QALY_ctr <- profile_b_QALY_int <- profile_b_QALY\n        profile_b_QALY_ctr[trt_pos] <- 0 #set profile for comparator\n        profile_b_QALY_int[trt_pos] <- 1 #set profile for reference\n        #define TCreg profile\n        if(profile_TC == \"default\"){\n          profile_b_TC <- apply(X_c, 2, mean, na.rm=T)\n        } else {profile_b_TC <- profile_TC}\n        profile_b_TC_ctr <- profile_b_TC_int <- profile_b_TC\n        profile_b_TC_ctr[trt_pos] <- 0 #set profile for comparator\n        profile_b_TC_int[trt_pos] <- 1 #set profile for reference\n        #extract coefficient estimates from each model\n        coeff_e[m,i] <- summary(model_MB_ec$eq[[1]])$coefficients[trt_pos,\"Estimate\"]\n        coeff_c[m,i] <- summary(model_MB_ec$eq[[2]])$coefficients[trt_pos,\"Estimate\"]        \n        #compute linear combination of parameters\n        em_e_ctr[m,i] <- t(profile_b_QALY_ctr) %*% summary(model_MB_ec$eq[[1]])$coefficients[,\"Estimate\"] \n        em_e_int[m,i] <- t(profile_b_QALY_int) %*% summary(model_MB_ec$eq[[1]])$coefficients[,\"Estimate\"] \n        em_c_ctr[m,i] <- t(profile_b_TC_ctr) %*% summary(model_MB_ec$eq[[2]])$coefficients[,\"Estimate\"] \n        em_c_int[m,i] <- t(profile_b_TC_int) %*% summary(model_MB_ec$eq[[2]])$coefficients[,\"Estimate\"]         \n      }\n    }\n  }\n  if(combine == \"BM\"){ #outer loop=Boot + inner loop=MI\n    #prepare empty objects to contain bootstrapped estimates\n    data_BM_list <- list()\n    coeff_c <- coeff_e <- matrix(NA, nrow = B, ncol = M)\n    em_c_ctr <- em_e_ctr <- matrix(NA, nrow = B, ncol = M)\n    em_c_int <- em_e_int <- matrix(NA, nrow = B, ncol = M)\n    data.dt <- data.table(x$data)\n    data_imp <- list()    \n    for(i in 1:B){\n      #sample with replacement from original data set\n      data_BM_list[[i]] <- as.data.frame(data.dt[sample(.N, n, replace = T)])\n      #split data by arm\n      data_BM_trt1 <- data.frame(data_BM_list[[i]][data_BM_list[[i]][,trt_name_e]==unique(x$data[,trt_name_e])[1],])\n      data_BM_trt2 <- data.frame(data_BM_list[[i]][data_BM_list[[i]][,trt_name_e]==unique(x$data[,trt_name_e])[2],])\n      #apply MI per arm based on arguments from mice objects provided as input\n      mice_data_boot_trt1 <- mice(data_BM_trt1, predictorMatrix = pm, \n                             method=meth,m = M, maxit = niter, print = FALSE)\n      mice_data_boot_trt2 <- mice(data_BM_trt2, predictorMatrix = pm, \n                                  method=meth,m = M, maxit = niter, print = FALSE)\n      #combine the imputed datasets across groups\n      mice_data_boot <- rbind(mice_data_boot_trt1, mice_data_boot_trt2)\n      for(m in 1:M){\n        #extract each imputed data set\n        data_imp[[m]] <- complete(mice_data_boot, m)\n        #fit model to each imputed data set\n        model_BM_ec <- systemfit(list(QALYreg = QALYreg, TCreg = TCreg), \n                  method=method, data=data_imp[[m]])  \n        #extract covariate values\n        X_e <- model.matrix(model_BM_ec$eq[[1]])\n        X_c <- model.matrix(model_BM_ec$eq[[2]])        \n        #define QALYreg profile\n        if(profile_QALY == \"default\"){\n          profile_b_QALY <- apply(X_e, 2, mean, na.rm=T)\n        } else {profile_b_QALY <- profile_QALY}\n        profile_b_QALY_ctr <- profile_b_QALY_int <- profile_b_QALY\n        profile_b_QALY_ctr[trt_pos] <- 0 #set profile for comparator\n        profile_b_QALY_int[trt_pos] <- 1 #set profile for reference\n        #define TCreg profile\n        if(profile_TC == \"default\"){\n          profile_b_TC <- apply(X_c, 2, mean, na.rm=T)\n        } else {profile_b_TC <- profile_TC}\n        profile_b_TC_ctr <- profile_b_TC_int <- profile_b_TC\n        profile_b_TC_ctr[trt_pos] <- 0 #set profile for comparator\n        profile_b_TC_int[trt_pos] <- 1 #set profile for reference        \n        #extract coefficient estimates from each model\n        coeff_e[i,m] <- summary(model_BM_ec$eq[[1]])$coefficients[trt_pos,\"Estimate\"]\n        coeff_c[i,m] <- summary(model_BM_ec$eq[[2]])$coefficients[trt_pos,\"Estimate\"]\n        #compute linear combination of parameters\n        em_e_ctr[i,m] <- t(profile_b_QALY_ctr) %*% summary(model_BM_ec$eq[[1]])$coefficients[,\"Estimate\"] \n        em_e_int[i,m] <- t(profile_b_QALY_int) %*% summary(model_BM_ec$eq[[1]])$coefficients[,\"Estimate\"] \n        em_c_ctr[i,m] <- t(profile_b_TC_ctr) %*% summary(model_BM_ec$eq[[2]])$coefficients[,\"Estimate\"] \n        em_c_int[i,m] <- t(profile_b_TC_int) %*% summary(model_BM_ec$eq[[2]])$coefficients[,\"Estimate\"]                 \n      }\n    }    \n  }\n  #create list objects to store all results \n  res_e_b_list <-list(\"Delta_e\"=coeff_e,\"mu_e_ctr\"=em_e_ctr,\"mu_e_int\"=em_e_int)\n  res_c_b_list <-list(\"Delta_c\"=coeff_c,\"mu_c_ctr\"=em_c_ctr,\"mu_c_int\"=em_c_int)\n  input_list <- list(\"data\"=x$data,\"method\"=method, \"trt_pos\"=trt_pos, \"QALYreg\"=QALYreg,\n                     \"TCreg\"=TCreg,\"profile_QALY_ctr\"=profile_b_QALY_ctr,\n                     \"profile_QALY_int\"=profile_b_QALY_int,\"profile_TC_ctr\"=profile_b_TC_ctr,\n                     \"profile_TC_int\"=profile_b_TC_int, \"combine\"=combine)\n  #compute overall list and return it as output from the function\n  res_ec_b_list <- list(\"QALY_boot\"=res_e_b_list,\"TC_boot\"=res_c_b_list,\"inputs\"=input_list)\n  class(res_ec_b_list) <- \"bootMICE\"\n  return(res_ec_b_list)\n}\n```\n:::\n\n\nNext, I show how the above function can be implemented to the generated data to fit either a BM or MB strategy. To avoid a too long computational time and due to the demonstrative purpose of the post, I will fix the number of bootstrap replications to $B=25$.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\n#combine MICE with bootstrapping based on OLS/SUR analyses to obtain distributions of statistics of interest \n#such as mean QALY/TC by arm and mean differences between groups\n#get MI and bootstrap results (25 iterations x 5 imputations = 125 replications)\n\n#version MB: first generate M imputed datasets (outer loop) and then within each\n#imputed dataset generate B bootstrap replications (inner loop)\nset.seed(2345)\nboot_mi_res <- boot_mi_ec(x=mice_fit, QALYreg = QALY~trt+u, \n                          TCreg = TC~trt+c,method = \"OLS\",B=25,\n                          combine = \"MB\")\n#summarise B x M matrix of estimates in two possible ways:\n#1)average across imputations \nMB1_res_Delta_e <- apply(boot_mi_res$QALY_boot$Delta_e, 2, mean)\nMB1_res_mu_e_ctr <- apply(boot_mi_res$QALY_boot$mu_e_ctr, 2, mean)\nMB1_res_mu_e_int <- apply(boot_mi_res$QALY_boot$mu_e_int, 2, mean)\nMB1_res_Delta_c <- apply(boot_mi_res$TC_boot$Delta_c, 2, mean)\nMB1_res_mu_c_ctr <- apply(boot_mi_res$TC_boot$mu_c_ctr, 2, mean)\nMB1_res_mu_c_int <- apply(boot_mi_res$TC_boot$mu_c_int, 2, mean)\n#2)average across imputations and bootstrap replicates\nMB2_res_Delta_e <- c(boot_mi_res$QALY_boot$Delta_e)\nMB2_res_mu_e_ctr <- c(boot_mi_res$QALY_boot$mu_e_ctr)\nMB2_res_mu_e_int <- c(boot_mi_res$QALY_boot$mu_e_int)\nMB2_res_Delta_c <- c(boot_mi_res$TC_boot$Delta_c)\nMB2_res_mu_c_ctr <- c(boot_mi_res$TC_boot$mu_c_ctr)\nMB2_res_mu_c_int <- c(boot_mi_res$TC_boot$mu_c_int)\n\n#version BM: first generate B bootstrap replications (outer loop) and then within each\n#bootstrapped dataset generate M imputations (inner loop)\nset.seed(2345)\nboot_mi_res <- boot_mi_ec(x=mice_fit, QALYreg = QALY~trt+u, \n                          TCreg = TC~trt+c,method = \"OLS\",B=25,\n                          combine = \"BM\")\n#summarise B x M matrix of estimates in two possible ways:\n#1)average across imputations \nBM1_res_Delta_e <- apply(boot_mi_res$QALY_boot$Delta_e, 1, mean)\nBM1_res_mu_e_ctr <- apply(boot_mi_res$QALY_boot$mu_e_ctr, 1, mean)\nBM1_res_mu_e_int <- apply(boot_mi_res$QALY_boot$mu_e_int, 1, mean)\nBM1_res_Delta_c <- apply(boot_mi_res$TC_boot$Delta_c, 1, mean)\nBM1_res_mu_c_ctr <- apply(boot_mi_res$TC_boot$mu_c_ctr, 1, mean)\nBM1_res_mu_c_int <- apply(boot_mi_res$TC_boot$mu_c_int, 1, mean)\n#2)average across imputations and bootstrap replicates\nBM2_res_Delta_e <- c(boot_mi_res$QALY_boot$Delta_e)\nBM2_res_mu_e_ctr <- c(boot_mi_res$QALY_boot$mu_e_ctr)\nBM2_res_mu_e_int <- c(boot_mi_res$QALY_boot$mu_e_int)\nBM2_res_Delta_c <- c(boot_mi_res$TC_boot$Delta_c)\nBM2_res_mu_c_ctr <- c(boot_mi_res$TC_boot$mu_c_ctr)\nBM2_res_mu_c_int <- c(boot_mi_res$TC_boot$mu_c_int)\n```\n:::\n\n\nFinally, we can quickly compare the generated incremental quantities $\\Delta_e$ distributions under each strategy and aggregation approach, for example using histograms. First, we consider using the averaged $B$ estimates across the $M$ imputations under either MB (red) or BM (blue).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nand then using all the $M\\times B$ estimates under either MB (red) or BM (blue)\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nSimilar functions that allow the implementation of MI and bootstrapping for GLMs and MLMs are also available from my [GitHub repository](https://github.com/AnGabrio/Code/tree/master/RHTAmethods), where there is also a separate file containing all well-wrapped functions that I showed in this and the last post for trial-based CE analyses. Thanks again for reading, and I hope this will be of help for some of you. Till next time!\n\n\n# References\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}