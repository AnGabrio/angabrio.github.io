{
  "hash": "1daef4f416e65c55d51817c53e9e7f19",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Rasch Model\"\ndescription: \"\"\nauthor:\n  - name: Andrea Gabrio\n    url: https://angabrio.github.io/agabriosite2/\n    orcid: 0000-0002-7650-4534\n    affiliation: Maastricht University\n    affiliation-url: https://www.maastrichtuniversity.nl/research/methodology-and-statistics\ndate: 2024-03-13\ncategories: [Quarto, R, Academia, IRT] # self-defined categories\n#citation: \n#  url: https://samanthacsik.github.io/posts/2022-10-24-my-blog-post/ \nimage: featured.png\ndraft: false # setting this to `true` will prevent your post from appearing on your listing page until you're ready!\n---\n\n\n![](featured.png){fig-align=\"center\"}\n\n\nHello everyone, and welcome back to my blog. Today I would like to resume a topic that I promised myself I will study more but which I kind of left alone for quite some time now. I initially introduced the topic a few months ago in another post, using a primary reference the book of [Jean-Paul Fox](https://www.jean-paulfox.com/) called [**Bayesian Item Response Modelling**](https://link.springer.com/book/10.1007/978-1-4419-0742-4#:~:text=The%20Bayesian%20approach%20has%20two,additional%20information%20can%20be%20used.). With this post I would like to take over from where I left and continue talking a bit about *Item Response Theory* (IRT).\n\nLast time I focussed on IRT models, I introduced the simplest type of model for binary IRT response data, called the **Rasch Model** or one-parameter logistic response model, in which the probability of a correct response is given by:\n\n$$\nP(Y_{ik}=1 | \\theta_i,b_k) = \\frac{\\text{exp}(\\theta_i - b_k)}{1+\\text{exp}(\\theta_i-b_k)},\n$$\n\nfor individual $i$ with ability level $\\theta_i$ and item $k$ with item-difficulty parameter $b_k$. Now, let's try to simulate some data according to the Rasch model. \n\nLet's start by considering a simple questionnaire example formed by $K=2$ dichotomous items, and for each of these the $i$-th respondent in the dataset may provide either a negative (e.g. wrong/failure) or positive (e.g. correct/success) response $Y_{ik}=0$ or $Y_{ik}=1$ according to some probability which in turn depends on some person-specific ability level $\\theta_i$ and item-specific difficulty level $b_k$. We proceed as follows:\n\n  1. Simulate item difficulties $b_k$ using a uniform distribution, i.e. $b_k\\sim \\text{Uniform}(a_b,b_b)$ for $k=1,K=2$.\n  \n  2. Simulate the person abilities $\\theta_i$ using a normal distribution, i.e. $\\theta_i \\sim \\text{Normal}(\\mu_{\\theta},\\sigma_{\\theta})$ for $i=1,\\ldots,N=100$.\n  \n  3. Use the generated values of $\\theta_i$ and $b_k$ to obtain $P(Y_{ik}=1 | \\theta_i,b_k)$, i.e. the probability of giving the correct response for the $i$-th person on the $k$-th item using the **Item Characteristic Curve** (ICC) equation of the Rasch model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(7689)\n\nK <- 2\nb <- runif(K,-1,1) \nN <- 10\ntheta <- rnorm(N,0,2)\ntemp <- matrix( rep( theta, length( b ) ) , ncol = length( b ) )\np_resp <- matrix(NA, nrow = N, ncol = K)\nfor(i in 1:N){\n for(k in 1:K){\n  p_resp[i,k] <- (exp(theta[i] - b[k])) / (1 + exp(theta[i] - b[k]))\n }\n}\nobs_resp <- matrix( sapply( c(p_resp), rbinom, n = 1, size = 1), ncol = length(b) )\n\n#put everything into a function\nsim_rasch <- function(N,K,a_b=-1,b_b=1,mu_theta=0,sigma_theta=2){\nb <- runif(K,a_b,b_b) \ntheta <- rnorm(N,mu_theta,sigma_theta)\ntemp <- matrix( rep( theta, length( b ) ) , ncol = length( b ) )\np_resp <- matrix(NA, nrow = N, ncol = K)\nfor(i in 1:N){\n for(k in 1:K){\n  p_resp[i,k] <- (exp(theta[i] - b[k])) / (1 + exp(theta[i] - b[k]))\n }\n}\n obs_resp <- matrix( sapply( c(p_resp), rbinom, n = 1, size = 1), ncol = length(b) )\n output <- list(\"y\"=obs_resp, \"p\"=p_resp, \"theta\"=theta, \"b\"=b)\n return(output)\n}\n\nobs_resp\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      [,1] [,2]\n [1,]    0    0\n [2,]    0    0\n [3,]    0    0\n [4,]    1    1\n [5,]    1    0\n [6,]    1    1\n [7,]    0    1\n [8,]    0    0\n [9,]    0    0\n[10,]    0    1\n```\n\n\n:::\n:::\n\n\nNow, let's put everything we have done into a function so that we can customise the output as much as we like, for example considering a sample of $N=25$ people who answer a set of $K=5$ dichotomous items:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(7689)\n\n#put everything into a function\nsim_rasch <- function(N,K,a_b=-1,b_b=1,mu_theta=0,sigma_theta=2){\nb <- runif(K,a_b,b_b) \ntheta <- rnorm(N,mu_theta,sigma_theta)\ntemp <- matrix( rep( theta, length( b ) ) , ncol = length( b ) )\np_resp <- matrix(NA, nrow = N, ncol = K)\nfor(i in 1:N){\n for(k in 1:K){\n  p_resp[i,k] <- (exp(theta[i] - b[k])) / (1 + exp(theta[i] - b[k]))\n }\n}\n obs_resp <- matrix( sapply( c(p_resp), rbinom, n = 1, size = 1), ncol = length(b) )\n output <- list(\"y\"=obs_resp, \"p\"=p_resp, \"theta\"=theta, \"b\"=b)\n return(output)\n}\n\ndata_sim <- sim_rasch(N=50,K=5)\n\n#extract observed data\ndata_sim$y\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      [,1] [,2] [,3] [,4] [,5]\n [1,]    0    0    0    1    1\n [2,]    0    0    1    0    1\n [3,]    0    0    0    0    0\n [4,]    1    1    1    1    1\n [5,]    1    1    0    1    1\n [6,]    1    1    1    1    1\n [7,]    0    0    1    0    0\n [8,]    1    1    1    1    1\n [9,]    1    1    1    1    1\n[10,]    1    0    1    0    1\n[11,]    0    0    0    0    0\n[12,]    1    0    0    0    0\n[13,]    0    0    0    1    0\n[14,]    1    1    1    1    1\n[15,]    1    1    1    1    1\n[16,]    0    1    0    0    1\n[17,]    0    0    0    0    0\n[18,]    0    1    0    0    1\n[19,]    1    1    1    1    1\n[20,]    0    0    0    0    1\n[21,]    1    1    0    1    0\n[22,]    0    0    0    0    0\n[23,]    0    0    1    0    0\n[24,]    0    0    0    1    0\n[25,]    0    0    1    1    1\n[26,]    0    0    0    0    0\n[27,]    0    0    1    1    1\n[28,]    0    0    1    0    0\n[29,]    1    1    1    1    1\n[30,]    0    1    0    0    0\n[31,]    1    1    1    1    1\n[32,]    0    0    1    0    1\n[33,]    0    0    0    0    1\n[34,]    0    0    0    1    1\n[35,]    1    0    1    0    1\n[36,]    1    0    1    1    1\n[37,]    1    0    1    0    1\n[38,]    1    1    1    1    1\n[39,]    0    0    0    1    1\n[40,]    1    1    1    1    1\n[41,]    0    0    0    0    0\n[42,]    0    0    0    0    1\n[43,]    0    0    1    0    0\n[44,]    1    1    0    0    1\n[45,]    0    0    0    1    0\n[46,]    1    1    1    1    1\n[47,]    1    0    1    0    1\n[48,]    1    1    1    1    1\n[49,]    0    1    0    1    0\n[50,]    0    0    1    1    0\n```\n\n\n:::\n:::\n\n\nOk cool, now that we simulated the data, let's try to use one of the many `R` packages to fit a Rasch model to the data and see whether the model fits them as it should be. For this purpose, I will use the `eRm` package, specifically dedicated to the fitting and checking of Rasch models to the data. I refer to [this webpage](http://publicifsv.sund.ku.dk/~kach/scaleval_IRT/Rasch-models-in-R.html) for a more in depth explanation of the package and its function, from which most of the stuff I will show is taken from. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#load package\nlibrary(eRm)\n\n#fit model to simulated item responses\nitems <- data_sim$y\nK <- ncol(items)\nN <- nrow(items)\ncolnames(items) <- c(sprintf(\"item%01d\", seq(1,K)))\n#fit the model\nraschfit <- RM(items)\n```\n:::\n\n\nAfter fitting the model and saving the output in the object `raschfit`, we can inspect the coefficient estimates of the model both in terms of person and item-specific parameters:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#print estimates\n\ni.param <- coef(raschfit)\n#item parameters/difficulties\ni.param\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nbeta item1 beta item2 beta item3 beta item4 beta item5 \n-0.4359822 -0.7641137  0.2419883  0.1154749  0.8426327 \n```\n\n\n:::\n\n```{.r .cell-code}\np.param <- person.parameter(raschfit)\n#person parameters/abilities\np.param\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nPerson Parameters:\n\n Raw Score   Estimate Std.Error\n         0 -2.5773973        NA\n         1 -1.4777665 1.1455225\n         2 -0.4349030 0.9460435\n         3  0.4371723 0.9454384\n         4  1.4776048 1.1439625\n         5  2.5743185        NA\n```\n\n\n:::\n\n```{.r .cell-code}\n#plot item and persons together\nplotPImap(raschfit)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nWe can also obtain the ICC function for each item. For example, let's say we want to show the ICC for item $2$ and $4$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#item 2\nplotICC(raschfit, item.subset = c(2), ask=F)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#item 4\nplotICC(raschfit, item.subset = c(4), ask=F)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n:::\n\n\nNext, it may be useful to test some of the key assumptions of the Rasch model to see whether the model seems to be reasonable for the data at hand. Among the most popular test procedures that are available in in the package, we can consider the following:\n\n  1) Andersen’s conditional Likelihood Ratio Test.\n\nIt is a surprising result that we can take our items and then get the correct estimates of all the item parameters $\\boldsymbol b=(b_1,\\ldots,b_K)$ in the any of these sub samples. This only work because we use conditional inference. It works if we divide the sample into two or more groups using any splitting criterion. We can do it in `eRm`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngr <- cut(\n  rowSums(items),\n  breaks=c(0,2,5),\n  include.lowest = TRUE)\nLRtest(raschfit, splitcr=gr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nAndersen LR-test: \nLR-value: 8.896 \nChi-square df: 4 \np-value:  0.064 \n```\n\n\n:::\n\n```{.r .cell-code}\n#graphically\nlr <- LRtest(raschfit, splitcr = gr, se = T)\nplotGOF(lr)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplotGOF(lr, conf=list(), xlim=c(-4,4), ylim=c(-5,5))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n:::\n\n\n  2) Wald test\n\nThe test allows for testing each item $k$. The idea is the same: divide sample into two subgroups. Item parameters should be invariant\n\n\n::: {.cell}\n\n```{.r .cell-code}\nWaldtest(raschfit, splitcr = gr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nWald test on item level (z-values):\n\n           z-statistic p-value\nbeta item1      -2.081   0.037\nbeta item2       1.385   0.166\nbeta item3       0.494   0.622\nbeta item4       1.729   0.084\nbeta item5      -0.391   0.696\n```\n\n\n:::\n:::\n\n\n  3) Infit and Outfit test statistics\n\nExpected response matrix obtained from $\\pi_{ij}=\\frac{\\text{exp}(\\hat{b}_k+\\hat{\\theta}_i)}{1+\\text{exp}(\\hat{b}_k+\\hat{\\theta}_i)}$, while residuals are defined as $e_{ik}=y_{ik}-\\pi_{ik}$. From these quantities, we can retrieve the two statistics: $\\text{INFIT}_k=w_k=\\frac{1}{N}\\frac{\\sum_i e^2_{ik}}{\\sum_i \\nu_{ik}}$ and $\\text{OUTFIT}_k=u_k=\\frac{1}{N}\\sum_i \\frac{e^2_{ik}}{\\nu_{ik}}$, where $\\nu_{ik}=\\pi_{ik}\\times (1-\\pi_{ik})$. The INFIT and OUTFIT item fit test statistics have expected value $1$. Informal evaluation: $0.7$ to $1.3$ is fine ($0.5$ to $1.5$ is OK). The interpretation of the OUTFIT statistic is sensitive against outlying observations e.g. when a very able person gets an easy item wrong. To calculate in `eRm` we have to use the `p.param` object:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nitemfit(p.param)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nItemfit Statistics: \n       Chisq df p-value Outfit MSQ Infit MSQ Outfit t Infit t Discrim\nitem1 20.869 30   0.892      0.673     0.689   -1.297  -1.771   2.353\nitem2 31.971 30   0.369      1.031     1.053    0.204   0.308  -0.228\nitem3 37.423 30   0.165      1.207     1.137    1.118   0.897  -0.921\nitem4 34.630 30   0.256      1.117     1.136    0.650   0.875  -1.691\nitem5 23.833 30   0.780      0.769     0.806   -1.198  -1.364   0.715\n```\n\n\n:::\n\n```{.r .cell-code}\n#use iarm package to shows p-values less than 0.05\nlibrary(iarm)\nout_infit(raschfit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n      Outfit se    pvalue padj sig  Infit se    pvalue padj  sig \nitem1 0.705  0.299 0.324  1         0.716 0.205 0.165  0.772     \nitem2 1.137  0.38  0.718  1         1.124 0.244 0.611  1         \nitem3 1.253  0.195 0.195  1         1.165 0.162 0.309  0.772     \nitem4 1.155  0.206 0.452  1         1.174 0.167 0.298  0.772     \nitem5 0.779  0.223 0.321  1         0.819 0.15  0.227  0.772     \n\nP value adjustment: BH\n```\n\n\n:::\n:::\n\n\nItem-total correlations and item-score correlations are routinely reported in classical test theory. We can use the simple structure in the Rasch model to compute the expected values of the item-score correlation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nitem_restscore(raschfit)\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      observed expected se     pvalue padj.BH sig\nitem1 0.8768   0.7233   0.0851 0.0714 0.3568     \nitem2 0.7057   0.7603   0.1295 0.6732 0.6732     \nitem3 0.5632   0.6538   0.1507 0.5476 0.6732     \nitem4 0.5770   0.6661   0.1446 0.5378 0.6732     \nitem5 0.7328   0.5992   0.1174 0.2550 0.6374     \n```\n\n\n:::\n:::\n\n\n  4) ICC plots compared to empirical ICC\n\nData with no missing values - score distribution:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- rowSums(items)\ntable(s)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ns\n 0  1  2  3  4  5 \n 6 12  9  8  2 13 \n```\n\n\n:::\n\n```{.r .cell-code}\nhist(s)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\nfit<-RM(items)\nppar <- person.parameter(raschfit)\n\n#one to one correspondence between y and theta\nplot(ppar)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#we look at the item 2\nplotICC(fit,\nitem.subset = c(2),\nempICC = list(\"raw\"),\nempCI = list(gamma=0.95, col=\"blue\")\n)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-3.png){width=672}\n:::\n:::\n\n\nThis plot shows the ICC for the selected item. The x-axis shows the ability continuum, the y-axis the response probability. The continuous line describes the probability to respond correctly to the problem given a level of ability. The difficulty of the item is where the probability of a correct response equals $0.5$. The option `empICC` equal to \"raw\" also plots the relative frequencies of positive responses for each rawscore group at the position of the corresponding ability level. The blue dotted lines represent the $95\\%$ confidence level for the relative frequencies and are shown if options are provided if the optional argument `empCI` is specified.\n\n  5) tests for local dependence\n\nTesting for local dependence can be done by removing an item, fitting the Rasch model to the remaining items, splitting with respect to the removed item. The general method for testing local dependence is to compute Yens $Q_3$ statistic, which proceeds as follows. Estimate $\\boldsymbol b$ and $\\boldsymbol \\theta$; compute the expected data matrix $\\boldsymbol E=E_{ik}=E(Y_{ik}\\mid \\theta_i=\\hat{\\theta}_i)=P(Y_{ik}=1\\mid \\theta_i=\\hat{\\theta}_i)$; compute the matrix of residuals $\\boldsymbol R=R_{ik}=\\frac{Y_{ik} - E_{ik}}{\\text{Var}(Y_{ik})}$; evaluate correlation between residuals. We use the `sirt` package for this\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <- sirt::rasch.mml2(items)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n------------------------------------------------------------\nSemiparametric Marginal Maximum Likelihood Estimation \nRaschtype Model with generalized logistic link function: alpha1= 0 , alpha2= 0  \n------------------------------------------------------------\n...........................................................\nIteration 1     2024-07-22 15:35:17.027667 \n   Deviance=302.8245\n    Maximum b parameter change=0.149448 \n...........................................................\nIteration 2     2024-07-22 15:35:17.029991 \n   Deviance=299.1961 | Deviance change=3.628433\n    Maximum b parameter change=0.036572 \n...........................................................\nIteration 3     2024-07-22 15:35:17.030829 \n   Deviance=296.505 | Deviance change=2.691082\n    Maximum b parameter change=0.036111 \n...........................................................\nIteration 4     2024-07-22 15:35:17.031601 \n   Deviance=294.5184 | Deviance change=1.986675\n    Maximum b parameter change=0.034245 \n...........................................................\nIteration 5     2024-07-22 15:35:17.032313 \n   Deviance=293.147 | Deviance change=1.371326\n    Maximum b parameter change=0.031046 \n...........................................................\nIteration 6     2024-07-22 15:35:17.03324 \n   Deviance=292.2506 | Deviance change=0.896385\n    Maximum b parameter change=0.027082 \n...........................................................\nIteration 7     2024-07-22 15:35:17.034008 \n   Deviance=291.6894 | Deviance change=0.561218\n    Maximum b parameter change=0.022895 \n...........................................................\nIteration 8     2024-07-22 15:35:17.034674 \n   Deviance=291.3492 | Deviance change=0.340225\n    Maximum b parameter change=0.018872 \n...........................................................\nIteration 9     2024-07-22 15:35:17.035317 \n   Deviance=291.1472 | Deviance change=0.202026\n    Maximum b parameter change=0.01525 \n...........................................................\nIteration 10     2024-07-22 15:35:17.035976 \n   Deviance=291.0282 | Deviance change=0.11894\n    Maximum b parameter change=0.012139 \n...........................................................\nIteration 11     2024-07-22 15:35:17.036595 \n   Deviance=290.958 | Deviance change=0.070237\n    Maximum b parameter change=0.009558 \n...........................................................\nIteration 12     2024-07-22 15:35:17.037218 \n   Deviance=290.916 | Deviance change=0.042003\n    Maximum b parameter change=0.00747 \n...........................................................\nIteration 13     2024-07-22 15:35:17.037848 \n   Deviance=290.8904 | Deviance change=0.025604\n    Maximum b parameter change=0.005808 \n...........................................................\nIteration 14     2024-07-22 15:35:17.038479 \n   Deviance=290.8744 | Deviance change=0.015958\n    Maximum b parameter change=0.004501 \n...........................................................\nIteration 15     2024-07-22 15:35:17.039254 \n   Deviance=290.8643 | Deviance change=0.010172\n    Maximum b parameter change=0.003481 \n...........................................................\nIteration 16     2024-07-22 15:35:17.039984 \n   Deviance=290.8576 | Deviance change=0.00662\n    Maximum b parameter change=0.002688 \n...........................................................\nIteration 17     2024-07-22 15:35:17.040703 \n   Deviance=290.8533 | Deviance change=0.004387\n    Maximum b parameter change=0.002073 \n...........................................................\nIteration 18     2024-07-22 15:35:17.041456 \n   Deviance=290.8503 | Deviance change=0.002952\n    Maximum b parameter change=0.001598 \n...........................................................\nIteration 19     2024-07-22 15:35:17.042538 \n   Deviance=290.8483 | Deviance change=0.002011\n    Maximum b parameter change=0.001231 \n...........................................................\nIteration 20     2024-07-22 15:35:17.043476 \n   Deviance=290.8469 | Deviance change=0.001384\n    Maximum b parameter change=0.000948 \n...........................................................\nIteration 21     2024-07-22 15:35:17.044301 \n   Deviance=290.8459 | Deviance change=0.000961\n    Maximum b parameter change=0.000729 \n...........................................................\nIteration 22     2024-07-22 15:35:17.045088 \n   Deviance=290.8453 | Deviance change=0.000673\n    Maximum b parameter change=0.000561 \n...........................................................\nIteration 23     2024-07-22 15:35:17.04583 \n   Deviance=290.8448 | Deviance change=0.000474\n    Maximum b parameter change=0.000431 \n...........................................................\nIteration 24     2024-07-22 15:35:17.046605 \n   Deviance=290.8445 | Deviance change=0.000336\n    Maximum b parameter change=0.000331 \n...........................................................\nIteration 25     2024-07-22 15:35:17.047385 \n   Deviance=290.8442 | Deviance change=0.000239\n    Maximum b parameter change=0.000255 \n...........................................................\nIteration 26     2024-07-22 15:35:17.048099 \n   Deviance=290.8441 | Deviance change=0.000171\n    Maximum b parameter change=0.000196 \n...........................................................\nIteration 27     2024-07-22 15:35:17.048813 \n   Deviance=290.8439 | Deviance change=0.000123\n    Maximum b parameter change=0.00015 \n...........................................................\nIteration 28     2024-07-22 15:35:17.049523 \n   Deviance=290.8438 | Deviance change=8.9e-05\n    Maximum b parameter change=0.000115 \n...........................................................\nIteration 29     2024-07-22 15:35:17.050303 \n   Deviance=290.8438 | Deviance change=6.5e-05\n    Maximum b parameter change=8.8e-05 \n------------------------------------------------------------\nStart: 2024-07-22 15:35:17.025159 \nEnd: 2024-07-22 15:35:17.05309 \nTime difference of 0.02793121 secs\nDifference: 0.02793121 \n------------------------------------------------------------\n```\n\n\n:::\n\n```{.r .cell-code}\nbeta <- mod$item$b\nmod.wle <- sirt::wle.rasch(dat= items , b = beta)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nWLE Reliability= 0.54 \n```\n\n\n:::\n\n```{.r .cell-code}\neta <- mod.wle$theta\n\n#and now we can calculate Yen’s Q3 statistic\nq3 <- sirt::Q3(dat = items, theta = eta , b = beta)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nYen's Q3 Statistic based on an estimated theta score \n*** 5 Items | 10 item pairs\n*** Q3 Descriptives\n     M     SD    Min    10%    25%    50%    75%    90%    Max \n-0.210  0.179 -0.540 -0.397 -0.336 -0.169 -0.073 -0.026  0.002 \n```\n\n\n:::\n:::\n\n\nThe conventional interpretation is that correlations should be close to zero. A large value is evidence of a problem with the scale, but since we do not know the asymptotic distribution we have to rely on a rule of thumb to decide when to reject model fit. Based on simulation studies, a value of $0.2$ is considered above the average and works well in many situations.\n\nSo, what do you think? pretty fun, isn't it? Next time I will delve into this a bit more and check the model fit. Another excuse to keep studying this super cool topic!\n\n\n\n\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}