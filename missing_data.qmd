---
title: "Missing Data"
format: dashboard
expandable: false
fig-align: center
scrolling: true
---

# {.sidebar width=25%}

## [Missing Data Methods]{style="font-size: 1.6rem"}

[In this rubric I attempt to give an overview on the research for handling missing values. If you are interested, I recommend visiting the website [R-mis-stastic](https://rmisstastic.netlify.app/), which provides references to many different approaches for handling missing data in a variety of research areas and applications.]{style="font-size: 1.2rem"}

# All 

::: {.listing}
[[Complete Case Analysis](missing_data/cca/cca.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Complete case analysis is the term used to describe a statistical analysis that only includes participants for which we do not have missing data on the variables of interest.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Explicit Single Imputation](missing_data/esi/esi.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Explicit Single imputation denotes a method based on an explicit model which replaces a missing datum with a single value. In this method the sample size is retrieved. However, the imputed values are assumed to be the real values that would have been observed when the data would have been complete.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Implicit Single Imputation](missing_data/isi/isi.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Implicit Single imputation denotes a method not based on an explicit model which replaces a missing datum with a single value. In this method the sample size is retrieved. However, the imputed values are assumed to be the real values that would have been observed when the data would have been complete.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Available Case Analysis](missing_data/aca/aca.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Available-case analysis also arises when a researcher simply excludes a variable or set of variables from the analysis because of their missing-data rates.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Inverse Probability Weighting](missing_data/ipw/ipw.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[The inverse probability weighting (IPW) approach preserves the semiparametric structure of the underlying model of substantive interest and clearly separates the model of substantive interest from the model used to account for the missing data.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Augmented Inverse Probability Weighting](missing_data/aipw/aipw.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Augmented Inverse Probability Weighting (AIPW) is a IPW technique that derives estimators using a combination of the propensity score and the regression model. This approach has the attractive doubly robust property that estimators are consistent as long as either the propensity score or the outcome regression model is correctly specified.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Weighting Adjustments](missing_data/wa/wa.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Weighting to compensate for nonresponse attaches weights to subjects included in the analysis to restore the representation in the original sample which is distorted because of missing values.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Multiple Imputation by Chained Equations](missing_data/mice/mice.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Multiple Imputation by Chained Equations (MICE) allows most models to be fit to a dataset with missing values on the independent and/or dependent variables, and provides rigorous standard errors for the fitted parameters. The basic idea is to treat each variable with missing values as the dependent variable in a regression, with some or all of the remaining variables as its predictors.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Joint Multiple Imputation](missing_data/jmi/jmi.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Joint Multiple Imputation (JOMO) commonly assumes that the incomplete variables follow a multivariate normal distribution, often referred to as multivariate normal imputation and, under this assumption, provides rigorous standard errors for the fitted parameters.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Introduction to Maximum Likelihood Estimation](missing_data/intro_mle/intro_mle.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Maximum Likelihood Estimation (MLE) is a method of estimating the parameters of a probability distribution by maximising a likelihood function, so that under the assumed statistical model the observed data is most probable.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Introduction to Bayesian Inference](missing_data/intro_bayes/intro_bayes.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Bayesian inference is a method of statistical inference in which Bayes theorem is used to update the probability for a hypothesis as more evidence or information becomes available.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Likelihood Based Inference with Incomplete Data](missing_data/likinf/likinf.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[When making inference with missing data, any statistical method must rely on either explicit or implicit assumptions about the mechanism which lead some of the values to be missing.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Expectation Maximisation Algorithm](missing_data/em/em.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[An Expectation–Maximization (EM) algorithm is an iterative method to find maximum likelihood or maximum a posteriori estimates of parameters in statistical models, where the model depends on unobserved latent variables.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Bayesian Iterative Simulation Methods](missing_data/bis/bis.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[The most popular class of Bayesian iterative methods is called Markov chain Monte Carlo (MCMC), which comprises different algorithms for sampling from a probability distribution. The more steps that are included, the more closely the distribution of the sample matches the actual desired distribution.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Likelihood Based Inference with Incomplete Data (Nonignorable)](missing_data/likinf_nig/likinf_nig.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Specific methods are required to make inference under nonignorable nonresponse assumptions, that is when the value of the variable that is missing is related to some values which are not observed by the analyst (e.g. the missing values themselves).]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Selection Models](missing_data/sm/sm.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Selection Models (SM) are typically used to handle nonignorable missingness. They factorise the joint likelihood of measurement process and missingness process into a marginal density of the measurement process and the density of the missingness process conditional on the outcomes, which describes the missing data selection based on the complete data.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Pattern Mixture Models](missing_data/pmm/pmm.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Pattern Mixture Models (PMM) are typically used to handle nonignorable missingness. They factorise the joint likelihood of measurement process and missingness process into a marginal density of the missingness process and the density of the measurement process conditional on the missing data patterns, where the model of interest is fitted for each pattern.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Shared Parameter Models](missing_data/spm/spm.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Shared Parameter Models (SPM) are typically used to handle nonignorable missingness. In these models a random effect is shared between the repeated measures model and the missing data mechanism model.]{style="font-size: 0.9rem; font-weight: lighter"}

:::


# Case Delete Methods 

::: {.listing}
[[Complete Case Analysis](missing_data/cca/cca.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Complete case analysis is the term used to describe a statistical analysis that only includes participants for which we do not have missing data on the variables of interest.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Available Case Analysis](missing_data/aca/aca.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Available-case analysis also arises when a researcher simply excludes a variable or set of variables from the analysis because of their missing-data rates.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

# Weighting Methods

::: {.listing}
[[Inverse Probability Weighting](missing_data/ipw/ipw.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[The inverse probability weighting (IPW) approach preserves the semiparametric structure of the underlying model of substantive interest and clearly separates the model of substantive interest from the model used to account for the missing data.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Augmented Inverse Probability Weighting](missing_data/aipw/aipw.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Augmented Inverse Probability Weighting (AIPW) is a IPW technique that derives estimators using a combination of the propensity score and the regression model. This approach has the attractive doubly robust property that estimators are consistent as long as either the propensity score or the outcome regression model is correctly specified.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Weighting Adjustments](missing_data/wa/wa.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Weighting to compensate for nonresponse attaches weights to subjects included in the analysis to restore the representation in the original sample which is distorted because of missing values.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

# Single Imputation Methods 

::: {.listing}
[[Explicit Single Imputation](missing_data/esi/esi.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Explicit Single imputation denotes a method based on an explicit model which replaces a missing datum with a single value. In this method the sample size is retrieved. However, the imputed values are assumed to be the real values that would have been observed when the data would have been complete.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Implicit Single Imputation](missing_data/isi/isi.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Implicit Single imputation denotes a method not based on an explicit model which replaces a missing datum with a single value. In this method the sample size is retrieved. However, the imputed values are assumed to be the real values that would have been observed when the data would have been complete.]{style="font-size: 0.9rem; font-weight: lighter"}

:::


# Multiple Imputation Methods 

::: {.listing}
[[Multiple Imputation by Chained Equations](missing_data/mice/mice.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Multiple Imputation by Chained Equations (MICE) allows most models to be fit to a dataset with missing values on the independent and/or dependent variables, and provides rigorous standard errors for the fitted parameters. The basic idea is to treat each variable with missing values as the dependent variable in a regression, with some or all of the remaining variables as its predictors.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Joint Multiple Imputation](missing_data/jmi/jmi.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Joint Multiple Imputation (JOMO) commonly assumes that the incomplete variables follow a multivariate normal distribution, often referred to as multivariate normal imputation and, under this assumption, provides rigorous standard errors for the fitted parameters.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

# Likelihood Based Ignorable Methods 

::: {.listing}
[[Introduction to Maximum Likelihood Estimation](missing_data/intro_mle/intro_mle.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Maximum Likelihood Estimation (MLE) is a method of estimating the parameters of a probability distribution by maximising a likelihood function, so that under the assumed statistical model the observed data is most probable.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Introduction to Bayesian Inference](missing_data/intro_bayes/intro_bayes.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Bayesian inference is a method of statistical inference in which Bayes theorem is used to update the probability for a hypothesis as more evidence or information becomes available.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Likelihood Based Inference with Incomplete Data](missing_data/likinf/likinf.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[When making inference with missing data, any statistical method must rely on either explicit or implicit assumptions about the mechanism which lead some of the values to be missing.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Expectation Maximisation Algorithm](missing_data/em/em.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[An Expectation–Maximization (EM) algorithm is an iterative method to find maximum likelihood or maximum a posteriori estimates of parameters in statistical models, where the model depends on unobserved latent variables.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Bayesian Iterative Simulation Methods](missing_data/bis/bis.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[The most popular class of Bayesian iterative methods is called Markov chain Monte Carlo (MCMC), which comprises different algorithms for sampling from a probability distribution. The more steps that are included, the more closely the distribution of the sample matches the actual desired distribution.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

# Likelihood Based Non-Ignorable Methods 

::: {.listing}
[[Likelihood Based Inference with Incomplete Data (Nonignorable)](missing_data/likinf_nig/likinf_nig.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Specific methods are required to make inference under nonignorable nonresponse assumptions, that is when the value of the variable that is missing is related to some values which are not observed by the analyst (e.g. the missing values themselves).]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Selection Models](missing_data/sm/sm.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Selection Models (SM) are typically used to handle nonignorable missingness. They factorise the joint likelihood of measurement process and missingness process into a marginal density of the measurement process and the density of the missingness process conditional on the outcomes, which describes the missing data selection based on the complete data.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Pattern Mixture Models](missing_data/pmm/pmm.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Pattern Mixture Models (PMM) are typically used to handle nonignorable missingness. They factorise the joint likelihood of measurement process and missingness process into a marginal density of the missingness process and the density of the measurement process conditional on the missing data patterns, where the model of interest is fitted for each pattern.]{style="font-size: 0.9rem; font-weight: lighter"}

:::

<br/> 

::: {.listing}
[[Shared Parameter Models](missing_data/spm/spm.qmd)]{style="font-size: 1.2rem; font-weight: bold"}

[Shared Parameter Models (SPM) are typically used to handle nonignorable missingness. In these models a random effect is shared between the repeated measures model and the missing data mechanism model.]{style="font-size: 0.9rem; font-weight: lighter"}

:::



