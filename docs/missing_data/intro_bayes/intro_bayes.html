<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2016-04-27">
<meta name="description" content="Bayesian inference is a method of statistical inference in which Bayes theorem is used to update the probability for a hypothesis as more evidence or information becomes available">

<title>Introduction to Bayesian Inference – Andrea Gabrio</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../img/icon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-54989a6d3e0684930921735f132eff69.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Andrea Gabrio</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../posts.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../projects.html"> 
<span class="menu-text">Research</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../publications.html"> 
<span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../software.html"> 
<span class="menu-text">Software</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../missing_data.html"> 
<span class="menu-text">Missing Data</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../tutorials.html"> 
<span class="menu-text">Tutorials</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../teaching.html"> 
<span class="menu-text">Teaching</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#bayesian-inference-for-complete-data" id="toc-bayesian-inference-for-complete-data" class="nav-link active" data-scroll-target="#bayesian-inference-for-complete-data">Bayesian Inference for Complete Data</a>
  <ul class="collapse">
  <li><a href="#bayes-rule" id="toc-bayes-rule" class="nav-link" data-scroll-target="#bayes-rule">Bayes’ Rule</a></li>
  <li><a href="#univariate-normal-example-known-variance" id="toc-univariate-normal-example-known-variance" class="nav-link" data-scroll-target="#univariate-normal-example-known-variance">Univariate Normal Example (known variance)</a></li>
  <li><a href="#univariate-normal-example-unknown-variance" id="toc-univariate-normal-example-unknown-variance" class="nav-link" data-scroll-target="#univariate-normal-example-unknown-variance">Univariate Normal Example (unknown variance)</a></li>
  <li><a href="#univariate-normal-example-unknown-mean-and-variance" id="toc-univariate-normal-example-unknown-mean-and-variance" class="nav-link" data-scroll-target="#univariate-normal-example-unknown-mean-and-variance">Univariate Normal Example (unknown mean and variance)</a></li>
  <li><a href="#multivariate-normal-example" id="toc-multivariate-normal-example" class="nav-link" data-scroll-target="#multivariate-normal-example">Multivariate Normal Example</a></li>
  </ul></li>
  <li><a href="#regression-models" id="toc-regression-models" class="nav-link" data-scroll-target="#regression-models">Regression Models</a></li>
  <li><a href="#generalised-linear-models" id="toc-generalised-linear-models" class="nav-link" data-scroll-target="#generalised-linear-models">Generalised Linear Models</a>
  <ul class="collapse">
  <li><a href="#poisson" id="toc-poisson" class="nav-link" data-scroll-target="#poisson">Poisson</a></li>
  <li><a href="#binomial" id="toc-binomial" class="nav-link" data-scroll-target="#binomial">Binomial</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Introduction to Bayesian Inference</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Quarto</div>
    <div class="quarto-category">R</div>
    <div class="quarto-category">Academia</div>
    <div class="quarto-category">Missing Data</div>
  </div>
  </div>

<div>
  <div class="description">
    Bayesian inference is a method of statistical inference in which Bayes theorem is used to update the probability for a hypothesis as more evidence or information becomes available
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 27, 2016</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<p>Bayesian inference offers a convenient framework to analyse missing data as it draws no distinction between missing values and parameters, both interprted as unobserved quantities who are associated with a joint posterior distribution conditional on the observed data. In this section, I review basic concepts of Bayesian inference based on fully observed data, with notation and structure mostly taken from <span class="citation" data-cites="gelman2013bayesian">Gelman et al. (<a href="#ref-gelman2013bayesian" role="doc-biblioref">2013</a>)</span>.</p>
<section id="bayesian-inference-for-complete-data" class="level2">
<h2 class="anchored" data-anchor-id="bayesian-inference-for-complete-data">Bayesian Inference for Complete Data</h2>
<p>Bayesian inference is the process of fitting a probability model to a set of data <span class="math inline">\(Y\)</span> and summarising the results by a probability distribution on the parameters <span class="math inline">\(\theta\)</span> of the model and on unobserved quantities <span class="math inline">\(\tilde{Y}\)</span> (e.g.&nbsp;predictions). Indeed, Bayesian statistical conclusions about <span class="math inline">\(\theta\)</span> (or <span class="math inline">\(\tilde{Y}\)</span>) are made in terms of probability statements, conditional on the observed data <span class="math inline">\(Y\)</span>, typically indicated with the notation <span class="math inline">\(p(\theta \mid y)\)</span> or <span class="math inline">\(p(\tilde{y} \mid y)\)</span>. Conditioning on the observed data is what makes Bayesian inference different from standard statistical approaches which are instead based on the retrospective evaluation of the procedures used to estimate <span class="math inline">\(\theta\)</span> (or <span class="math inline">\(\tilde{y}\)</span>) over the distribution of possible <span class="math inline">\(y\)</span> values conditional on the “true” unknown value of <span class="math inline">\(\theta\)</span>.</p>
<section id="bayes-rule" class="level3">
<h3 class="anchored" data-anchor-id="bayes-rule">Bayes’ Rule</h3>
<p>In order to make probability statements about <span class="math inline">\(\theta\)</span> given <span class="math inline">\(y\)</span>, we start with a model providing a <em>joint probability distribution</em> <span class="math inline">\(p(\theta,y)\)</span>. Thus, the joint probability mass or density function can be written as a product of two densities that are often referred to as the <em>prior distribution</em> <span class="math inline">\(p(\theta)\)</span> and the <em>sampling distribution</em> <span class="math inline">\(p(y \mid \theta)\)</span>, respectively:</p>
<p><span class="math display">\[
p(\theta,y) = p(\theta)p(y \mid \theta),
\]</span></p>
<p>and conditioning on the observed values of <span class="math inline">\(y\)</span>, using the basic property of conditional probability known as <em>Bayes’ rule</em>, yields the <em>posterior distribution</em></p>
<p><span class="math display">\[
p(\theta \mid y) = \frac{p(\theta,y)}{p(y)} = \frac{p(\theta)p(y \mid \theta)}{p(y)},
\]</span></p>
<p>where <span class="math inline">\(p(y)=\sum_{\theta \in \Theta}p(\theta)p(y\mid \theta)\)</span> is the sum (or integral in the case of continous <span class="math inline">\(\theta\)</span>) over all possible values of <span class="math inline">\(\theta\)</span> in the sample space <span class="math inline">\(\Theta\)</span>. We can approximate the above equation by omitting the factor <span class="math inline">\(p(y)\)</span> which does not depend on <span class="math inline">\(\theta\)</span> and, given <span class="math inline">\(y\)</span>, can be considered as fixed, yielding the <em>unnormalised posterior density</em></p>
<p><span class="math display">\[
p(\theta \mid y) \propto p(\theta) p(y \mid \theta),
\]</span></p>
<p>with the purpose of the analysis being to develop the model <span class="math inline">\(p(\theta,y)\)</span> and adequately summarise <span class="math inline">\(p(\theta \mid y)\)</span>.</p>
</section>
<section id="univariate-normal-example-known-variance" class="level3">
<h3 class="anchored" data-anchor-id="univariate-normal-example-known-variance">Univariate Normal Example (known variance)</h3>
<p>Let <span class="math inline">\(y=(y_1,\ldots,y_n)\)</span> denote an independent and identially distributed sample of <span class="math inline">\(n\)</span> units, which are assumed to come from a Normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, whose sampling density function is</p>
<p><span class="math display">\[
p(y \mid \mu)=\frac{1}{\sqrt{\left(2\pi\sigma^2\right)^n}}\text{exp}\left(-\frac{1}{2}\sum_{i=1}^n \frac{(y_i-\mu)^2}{\sigma^2} \right),
\]</span></p>
<p>where for the moment we assume the variance <span class="math inline">\(\sigma^2\)</span> to be known (i.e.&nbsp;constant). Consider now a prior probability distribution for the mean parameter <span class="math inline">\(p(\mu)\)</span>, which belongs to the family of <em>conjugate prior densities</em>, for example a Normal distribution, and parameterised in terms of a prior mean <span class="math inline">\(\mu_0\)</span> and variance <span class="math inline">\(\sigma^2_0\)</span>. Thus, its prior density function is</p>
<p><span class="math display">\[
p(\mu) = \frac{1}{\sqrt{2\pi\sigma^2_0}}\text{exp}\left(-\frac{1}{2}\frac{(\mu -\mu_0)^2}{\sigma^2} \right),
\]</span></p>
<p>under the assumption tha the hyperparameters <span class="math inline">\(\mu_0\)</span> and <span class="math inline">\(\sigma^2_0\)</span> are known. The conjugate prior density implies that the posterior distribution for <span class="math inline">\(\mu\)</span> (with <span class="math inline">\(\sigma^2\)</span> assumed constant) belongs to the same family of distributions of the sampling function, that is Normal, but some algebra is required to reveal its specific form. In particular, the posterior density is</p>
<p><span class="math display">\[
p(\mu \mid y) = \frac{p(\mu)p(y\mid \mu)}{p(y)} \propto \frac{1}{\sqrt{2\pi\sigma^2_0}}\frac{1}{\sqrt{\left(2\pi\sigma^2\right)^n}}\text{exp}\left(-\frac{1}{2} \left[\frac{(\mu - \mu_0)^2}{\sigma^2_0} + \sum_{i=1}^n\frac{(y_i-\mu)^2}{\sigma^2} \right] \right).
\]</span></p>
<p>Exapanding the components, collecting terms and completing the square in <span class="math inline">\(\mu\)</span> gives</p>
<p><span class="math display">\[
p(\mu \mid y) \propto \text{exp}\left(-\frac{(\mu - \mu_1)}{2\tau^2_1} \right),
\]</span></p>
<p>that is the posterior distribution of <span class="math inline">\(\mu\)</span> given <span class="math inline">\(y\)</span> is Normal with posterior mean <span class="math inline">\(\mu_1\)</span> and variance <span class="math inline">\(\tau^2_1\)</span>, where</p>
<p><span class="math display">\[
\mu_1 = \frac{\frac{1}{\tau^2_0}\mu_0 + \frac{n}{\sigma^2}\bar{y}}{\frac{1}{\tau^2_0} + \frac{n}{\sigma^2}} \;\;\; \text{and} \;\;\; \frac{1}{\tau^2_1}=\frac{1}{\tau^2_0} + \frac{n}{\sigma^2}.
\]</span></p>
<p>We can see that the posterior distribution depends on <span class="math inline">\(y\)</span> only through the sample mean <span class="math inline">\(\bar{y}=\sum_{i=1}^ny_i\)</span>, which is a <em>sufficient statistic</em> in this model. When working with Normal distributions, the inverse of the variance plays a prominent role and is called the <em>precision</em> and, from the above expressions, it can be seen that for normal data and prior, the posterior precision <span class="math inline">\(\frac{1}{\tau^2_1}\)</span> equals the sum of the prior precision <span class="math inline">\(\frac{1}{\tau^2_0}\)</span> and the sampling precision <span class="math inline">\(\frac{n}{\sigma^2}\)</span>. Thus, when <span class="math inline">\(n\)</span> is large, the posterior precision is largely dominated by <span class="math inline">\(\sigma^2\)</span> and the sample mean <span class="math inline">\(\bar{y}\)</span> compared to the corresponding prior parameters. In the specific case where <span class="math inline">\(\tau^2_0=\sigma^2\)</span>, the prior has the same weight as one extra observation with the value of <span class="math inline">\(\mu_0\)</span> and, as <span class="math inline">\(n\rightarrow\infty\)</span>, we have that <span class="math inline">\(p(\mu\mid y)\approx N\left(\mu \mid \bar{y},\frac{\sigma^2}{n}\right)\)</span>.</p>
</section>
<section id="univariate-normal-example-unknown-variance" class="level3">
<h3 class="anchored" data-anchor-id="univariate-normal-example-unknown-variance">Univariate Normal Example (unknown variance)</h3>
<p>For <span class="math inline">\(p(y \mid \mu,\sigma^2)=N(y \mid \mu, \sigma^2)\)</span> with <span class="math inline">\(\mu\)</span> known and <span class="math inline">\(\sigma^2\)</span> unknown, the sampling distribution for a vector <span class="math inline">\(y\)</span> of <span class="math inline">\(n\)</span> units is</p>
<p><span class="math display">\[
p(y \mid \sigma^2)=\frac{1}{\sqrt{\left(2\pi\sigma^2\right)^n}}\text{exp}\left(-\frac{1}{2}\sum_{i=1}^n \frac{(y_i-\mu)^2}{\sigma^2} \right),
\]</span></p>
<p>with the corresponding conjugate prior for <span class="math inline">\(\sigma^2\)</span> being the Inverse-Gamma distribution <span class="math inline">\(\Gamma^{-1}(\alpha,\beta)\)</span> with density function</p>
<p><span class="math display">\[
p(\sigma^2) \propto (\sigma^2)^{-(\alpha+1)}\text{exp}\left(-\frac{\beta}{\sigma^2}\right),
\]</span></p>
<p>indexed by the hyperparameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. A convenient parameterisation is as a Scaled Inverse-Chi Squared distribution <span class="math inline">\(\text{Inv-}\chi^2(\sigma^2_0,\nu_0)\)</span> with scale and degrees of freedom parameters <span class="math inline">\(\sigma^2_0\)</span> and <span class="math inline">\(\nu_0\)</span>, respectively. This means that the prior on <span class="math inline">\(\sigma^2\)</span> corresponds to the distribution of <span class="math inline">\(\frac{\sigma^2_0 \nu_0}{X}\)</span>, where <span class="math inline">\(X\sim \chi^2_{\nu_0}\)</span> random variable. After some calculations, the resulting posterior for <span class="math inline">\(\sigma^2\)</span> is</p>
<p><span class="math display">\[
p(\sigma^2 \mid y) \propto (\sigma^2)^\left(\frac{n+\nu_0}{2}+1\right)\text{exp}\left(-\frac{\nu_0 \sigma^2_0 + n \nu}{2\sigma^2} \right)
\]</span></p>
<p>where <span class="math inline">\(\nu=\frac{1}{n}\sum_{i=1}^n(y_i-\mu)^2\)</span>. This corresponds to say that</p>
<p><span class="math display">\[
\sigma^2 \mid y \sim \text{Inv-}\chi^2\left(\nu_0 +n, \frac{\nu_0\sigma^2_0+n\nu}{\nu_0 + n} \right),
\]</span></p>
<p>with scale equal to the degrees of freedom-weighted average of the prior and data scales and degrees of freedom equal to the sum of the prior and data degrees of freedom.</p>
</section>
<section id="univariate-normal-example-unknown-mean-and-variance" class="level3">
<h3 class="anchored" data-anchor-id="univariate-normal-example-unknown-mean-and-variance">Univariate Normal Example (unknown mean and variance)</h3>
<p>Suppose now that both the mean and variance parameters are unknown such that</p>
<p><span class="math display">\[
p(y \mid \mu, \sigma^2) \sim N(\mu, \sigma^2),
\]</span></p>
<p>and that the interest is centred on making inference about <span class="math inline">\(\mu\)</span>, that is we seek the conditional posterior distribution of the parameters of interest given the observed data <span class="math inline">\(p(\mu \mid y)\)</span>. This can be derived from the joint posterior distribution density <span class="math inline">\(p(\mu, \sigma^2 \mid y)\)</span> by averaging over all possible values of <span class="math inline">\(\sigma^2\)</span>, that is</p>
<p><span class="math display">\[
p(\mu \mid y)=\int p(\mu, \sigma^2 \mid y)d\sigma^2,
\]</span></p>
<p>or, alternatively, the joint posterior can be factored as the product of the marginal distribution of one parameter and the conditional distribution of the other given the former and then taking the average over the values of the “nuisance” parameter</p>
<p><span class="math display">\[
p(\mu \mid y)=\int p(\mu \mid \sigma^2, y)p(\sigma^2 \mid y)d\sigma^2.
\]</span></p>
<p>The integral forms are rarely computed in practice but this expression helps us to understand that posterior distributions can be expressed in terms of the product of marginal and conditional densities, first drawing <span class="math inline">\(\sigma^2\)</span> from its marginal and then <span class="math inline">\(\mu\)</span> from its conditional given the drawn value of <span class="math inline">\(\sigma^2\)</span>, so that the integration is indirectly performed. For example, consider the Normal model with both unknown mean and variance and assume a vague prior density <span class="math inline">\(p(\mu,\sigma^2)\propto (\sigma^2)^{-1}\)</span> (corresponding to uniform prior on <span class="math inline">\((\mu, \log\sigma)\)</span>), then the joint posterior distribution is proportional to the sampling distribution multiplied by the factor <span class="math inline">\((\sigma^2)^{-1}\)</span>, that is</p>
<p><span class="math display">\[
p(\mu,\sigma^2 \mid y)\propto \sigma^{-n-2}\text{exp}\left(-\frac{1}{2\sigma^2}\left[(n-1)s^2+n(\bar{y}-\mu)^2 \right] \right),
\]</span></p>
<p>where <span class="math inline">\(s^2=\frac{1}{n-1}\sum_{i=1}^n(y_i-\bar{y})^2\)</span> is the sample variance. Next, the conditional posterior density <span class="math inline">\(p(\mu \mid \sigma^2)\)</span> can be shown to be equal to</p>
<p><span class="math display">\[
p(\mu \mid \sigma^2,y) \sim N(\bar{y},\frac{\sigma^2}{n}),
\]</span></p>
<p>while the marginal posterior <span class="math inline">\(p(\sigma^2 \mid y)\)</span> can be obtained by averaging the joint <span class="math inline">\(p(\mu,\sigma^2\mid y)\)</span> over <span class="math inline">\(\mu\)</span>, that is</p>
<p><span class="math display">\[
p(\sigma^2 \mid y)\propto \int \left(\sigma^{-n-2}\text{exp}\left(-\frac{1}{2\sigma^2}\left[(n-1)s^2+n(\bar{y}-\mu)^2 \right] \right)\right)d\mu,
\]</span></p>
<p>which leads to</p>
<p><span class="math display">\[
p(\sigma^2 \mid ,y) \sim \text{Inv-}\chi^2(n-1,s^2).
\]</span></p>
<p>Typically, <span class="math inline">\(\mu\)</span> represents the estimand of interest and the obejective of the analysis is therefore to make inference about the marginal distribution <span class="math inline">\(p(\mu \mid y)\)</span>, which can be obtained by integrating <span class="math inline">\(\sigma^2\)</span> out of the joint posterior</p>
<p><span class="math display">\[
p(\mu \mid y)=\int_{0}^{\infty}p(\mu,\sigma^2\mid y)d\sigma^2 \propto \left[1+\frac{n(\mu-\bar{y})}{(n-1)s^2} \right]
\]</span></p>
<p>which corresponds to a Student-<span class="math inline">\(t\)</span> density with <span class="math inline">\(n-1\)</span> degrees of freedom</p>
<p><span class="math display">\[
p(\mu \mid y)\sim t_{n-1}\left(\bar{y},\frac{s^2}{n}\right)
\]</span></p>
</section>
<section id="multivariate-normal-example" class="level3">
<h3 class="anchored" data-anchor-id="multivariate-normal-example">Multivariate Normal Example</h3>
<p>Similar considerations to those applied to the univariate case can be extended to the multivariate case when <span class="math inline">\(y\)</span> is formed by <span class="math inline">\(J\)</span> components coming from the Multivariate Normal distribution</p>
<p><span class="math display">\[
p(y\mid \mu, \Sigma) \sim N(\mu, \Sigma),
\]</span></p>
<p>where <span class="math inline">\(\mu\)</span> is a vector of length <span class="math inline">\(J\)</span> and <span class="math inline">\(\Sigma\)</span> is a <span class="math inline">\(J\times J\)</span> covariance matrix, which is symmetric and positive definite. The sampling distribution for a sample of <span class="math inline">\(n\)</span> units is</p>
<p><span class="math display">\[
p(y\mid \mu, \Sigma) \propto \mid \Sigma \mid^{-n/2}\text{exp}\left(-\frac{1}{2}\sum_{i=1}^n(y_i-\mu)^{T}\Sigma^{-1}(y_i-\mu) \right),
\]</span></p>
<p>As with the univariate normal model, we can derive the posterior distribution for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Sigma\)</span> according to the factorisation used of the joint posterior and the prior distributions specified. For example, using the conjugate normal prior for the mean <span class="math inline">\(p(\mu)\sim N(\mu_0,\Sigma_0)\)</span>, given <span class="math inline">\(\Sigma\)</span> known, the posterior can be shown to be</p>
<p><span class="math display">\[
p(\mu \mid y) \sim N(\mu_1,\Sigma_1),
\]</span></p>
<p>where the posterior mean is a weighted average of the data and prior mean with weights given by the data and prior precision matrices <span class="math inline">\(\mu_1=(\Sigma^{-1}_0+n\Sigma^{-1})^{-1} (\Sigma_0^{-1}\mu_0 + n\Sigma^{-1}\bar{y})\)</span>, and the posterior precision is the sum of the data and prior precisions <span class="math inline">\(\Sigma^{-1}_1=\Sigma^{-1}_0+n\Sigma^{-1}\)</span>.</p>
<p>In the situation in which both <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\Sigma\)</span> are unknown, convenient conjugate prior distributions which generalise those used in the univariate case are the Inverse-Wishart for the covariance matrix <span class="math inline">\(\Sigma\sim \text{Inv-Wishart}(\Lambda_0,\nu_0)\)</span> and the Multivariate Normal for the mean <span class="math inline">\(\mu\sim N(\mu_0, \Sigma_0)\)</span>, where <span class="math inline">\(\nu_0\)</span> and <span class="math inline">\(\Lambda_0\)</span> represent the degrees of freedom and the scale matrix for the Inverse-Wishart distribution, while <span class="math inline">\(\mu_0\)</span> and <span class="math inline">\(\Sigma_0=\frac{\Sigma}{\kappa_0}\)</span> are the prior mean and covariance matrix for the Multivariate Normal. Woking out the form of the posterior, it can be shown that the joint posterior distribution has the same form of the sampling distribution with parameters</p>
<p><span class="math display">\[
p(\mu \mid \Sigma, y) \sim N(\mu_1,\Sigma_1) \;\;\; \text{and} \;\;\; p(\Sigma \mid y) \sim \text{Inv-Wishart}(\Lambda_1,\nu_1),
\]</span></p>
<p>where <span class="math inline">\(\Sigma_1=\frac{\Sigma}{\kappa_1}\)</span>, <span class="math inline">\(\mu_1=\frac{1}{\kappa_0+n}\mu_0+\frac{n}{\kappa_0+n}\bar{y}\)</span>, <span class="math inline">\(\kappa_1=\kappa_0+n\)</span>, <span class="math inline">\(\nu_1=\nu_0+n\)</span>, and <span class="math inline">\(\Lambda_1=\Lambda_0+\sum_{i=1}^n(y_i-\bar{y})(y_i-\bar{y})^T+\frac{\kappa_0 n}{\kappa_0+n}(\bar{y}-\mu_0)(\bar{y}-\mu_0)^2\)</span>.</p>
</section>
</section>
<section id="regression-models" class="level2">
<h2 class="anchored" data-anchor-id="regression-models">Regression Models</h2>
<p>Suppose the data consist in <span class="math inline">\(n\)</span> units measured on an outcome variable <span class="math inline">\(y\)</span> and a set of <span class="math inline">\(J\)</span> covariates <span class="math inline">\(X=(x_{1},\ldots,x_{J})\)</span> and assume that the distribution of <span class="math inline">\(y\)</span> given <span class="math inline">\(x\)</span> is Normal with mean <span class="math inline">\(\mu_i=\beta_0+\sum_{j=1}^J\beta_jx_{ij}\)</span> and variance <span class="math inline">\(\sigma^2\)</span></p>
<p><span class="math display">\[
p(y \mid \beta,\sigma^2,X) \sim N(X\beta,\sigma^2I),
\]</span></p>
<p>where <span class="math inline">\(\beta=(\beta_0,\ldots,\beta_J)\)</span> is the set of regression coefficients and <span class="math inline">\(I\)</span> is the <span class="math inline">\(n\times n\)</span> identity matrix. Within the normal regression model, a convenient vague prior distribution is uniform on <span class="math inline">\((\beta,\log\sigma)\)</span></p>
<p><span class="math display">\[
p(\beta,\sigma^2)\propto\sigma^{-2}.
\]</span></p>
<p>As with normal distributions with unknown mean and variance we can first determine the marginal posterior of <span class="math inline">\(\sigma^2\)</span> and factor the joint posterior as <span class="math inline">\(p(\beta,\sigma^2)=p(\beta \mid \sigma^2, y)p(\sigma^2 \mid y)\)</span> (omit X for simplicity). Then, the conditional distribtuion <span class="math inline">\(p(\beta \mid \sigma^2,y)\)</span> is Normal</p>
<p><span class="math display">\[
p(\beta \mid \sigma^2, y) \sim N(\hat{\beta},V_{\beta}\sigma^2),
\]</span></p>
<p>where <span class="math inline">\(\hat{\beta}=(X^{T}X)^{-1}(X^{T}y)\)</span> and <span class="math inline">\(V_{\beta}=(X^{T}X)^{-1}\)</span>. The marginal posterior <span class="math inline">\(p(\sigma^2 \mid y)\)</span> has a scaled Inverse-<span class="math inline">\(\chi^2\)</span> form</p>
<p><span class="math display">\[
p(\sigma^2\mid y) \sim \text{Inv-}\chi^2(n-J,s^2),
\]</span></p>
<p>where <span class="math inline">\(s^2=\frac{1}{n-J}(y-X\hat{\beta})^{T}(y-X\hat{\beta})\)</span>. Finally, the marginal posterior <span class="math inline">\(p(\beta \mid y)\)</span>, averaging over <span class="math inline">\(\sigma^2\)</span>, is multivariate <span class="math inline">\(t\)</span> with <span class="math inline">\(n-J\)</span> degrees of freedom, even though in practice since we can characterise the joint posterior by drawing from <span class="math inline">\(p(\sigma^2)\)</span> and then from <span class="math inline">\(p(\beta \mid \sigma^2)\)</span>. When the analysis is based on improper priors (do not have finite integral), it is important to check that the posterior is proper. In the case of the regression model, the posterior for <span class="math inline">\(\beta \mid \sigma^2\)</span> is proper only if the number of observations is larger than the number of parameters <span class="math inline">\(n&gt;J\)</span>, and that the rank of <span class="math inline">\(X\)</span> equals <span class="math inline">\(J\)</span> (i.e.&nbsp;the columns of <span class="math inline">\(X\)</span> are linearly independent) in order for all <span class="math inline">\(J\)</span> coefficients to be uniquely identified from the data.</p>
</section>
<section id="generalised-linear-models" class="level2">
<h2 class="anchored" data-anchor-id="generalised-linear-models">Generalised Linear Models</h2>
<p>The purpose of <em>Generalised Linear Models</em>(GLM) is to extend the idea of linear modelling to cases for which the linear relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(E[y\mid X]\)</span> or the Normal distribution is not appropriate. GLMs are specified in three stages</p>
<ol type="1">
<li><p>Choose the linear predictor <span class="math inline">\(\eta=X\beta\)</span></p></li>
<li><p>Choose the <em>link fuction</em> <span class="math inline">\(g()\)</span> that relates the linear predictor to the mean of the outcome variable <span class="math inline">\(\mu=g^{-1}(\eta)\)</span></p></li>
<li><p>Choose the random component specifying the distribution of <span class="math inline">\(y\)</span> with mean <span class="math inline">\(E[y\mid X]\)</span></p></li>
</ol>
<p>Thus, the mean of the distribution of <span class="math inline">\(y\)</span> given <span class="math inline">\(X\)</span> is determined as <span class="math inline">\(E[y\mid X]=g^{-1}(X\beta)\)</span>. The Normal linear model can be thought as a special case of GLMs where the link function is the identity <span class="math inline">\(g(\mu)=\mu\)</span> and the random component is normally distributed. Perhaps, the most commonly used GLMs are those based on Poisson and Binomial distributions to analyse count and binary data, respectively.</p>
<section id="poisson" class="level3">
<h3 class="anchored" data-anchor-id="poisson">Poisson</h3>
<p>Counted data are often modelled using Poisson regression models which assume that <span class="math inline">\(y\)</span> is distributed according to a Poisson distribution with mean <span class="math inline">\(\mu\)</span>. The link function is typically chosen to be the logarithm so that <span class="math inline">\(\log \mu = X\beta\)</span> and the distribution of the data has density</p>
<p><span class="math display">\[
p(y\mid \beta)=\prod_{i=1}^n \frac{1}{y_i}\text{exp}\left(-\text{e}^{(\eta_i)}(\text{exp}(\eta_i))^{y_i}\right),
\]</span></p>
<p>where <span class="math inline">\(\eta_i=(X\beta)_i\)</span> is the linear predictor for the <span class="math inline">\(i-\)</span>th unit.</p>
</section>
<section id="binomial" class="level3">
<h3 class="anchored" data-anchor-id="binomial">Binomial</h3>
<p>Suppose there are some binomial data <span class="math inline">\(y_i \sim \text{Bin}(n_i,\mu_i)\)</span>, with <span class="math inline">\(n_i\)</span> known. It is common to specify the model in terms of the mean of the proportions <span class="math inline">\(\frac{y_i}{n_i}\)</span> rather than the mean of <span class="math inline">\(y_i\)</span>. Choosing the logit tranformation of the probability of success <span class="math inline">\(g(\mu_i)=\log\left(\frac{\mu_i}{1-\mu_i}\right)\)</span> as the link function leads to the logistic regression where data have distribution</p>
<p><span class="math display">\[
p(y \mid \beta)=\prod_{i=1}^n {n_i \choose y_i} {e^{\eta_i} \choose 1+e^{\eta_i}}^{y_i} {1 \choose 1+e^{\eta_i}}^{n_i-y_i}.
\]</span></p>
<p>The link functions used in the previous models are known as the <em>canonical link</em> functions for each family of distributions, which is the function of the mean parameter that appears in the exponent of the exponential family form of the probability density. However, it is also possible to use link functions which are not canonical.</p>
</section>
</section>
<section id="references" class="level1">




</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-gelman2013bayesian" class="csl-entry" role="listitem">
Gelman, Andrew, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B Rubin. 2013. <em>Bayesian Data Analysis</em>. Chapman; Hall/CRC.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Copyright 2024, Andrea Gabrio</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p>Built with <a href="https://quarto.org/">Quarto</a></p>
</div>
  </div>
</footer>




</body></html>